{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriciosantana/nlp/blob/main/AKCIT_NLP_M6_Colab_Unidade_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfevqw7Eyf76"
      },
      "source": [
        "# Objetivos de Aprendizagem\n",
        "\n",
        "## 3.1  TF-IDF\n",
        "\n",
        "O procedimento descrito pela técnica *Count Vectorizer* é simples e bastante poderoso, mas tem uma limitação principal. [Manning et al. 2008](https://nlp.stanford.edu/IR-book/information-retrieval-book.html) descrevem que nele 'todos os termos são considerados igualmente importantes quando se trata de avaliar relevância'. Portanto, uma melhoria nesse sentido seria ponderar a computação de características dos dados textuais levando em consideração a frequência de cada palavra do exemplo considerado e no corpus como um todo. Isso permitiria que os algoritmos pudessem obter informações mais relevantes, mesmo quando lidando com dados textuais muito grandes. Isso é conhecido como *Term Frequency - Inverse Document Frequency*, ou TF-IDF, e também é uma técnica *bag-of-words*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frfvWRHk0Czc"
      },
      "source": [
        "Para ilustrar essa questão do que significa *relevância*, consideremos as seguintes frases em um contexto de uma tarefa de análise de sentimentos:\n",
        "\n",
        "1. Eu adorei o último jogo do Corinthians. Foi muito melhor que no jogo anterior, com mudanças táticas importantes que impactaram no estilo de jogo do time. (Sentimento positivo)\n",
        "2. Eu detestei o novo modo de jogo do Call of Duty. (Sentimento negativo)\n",
        "\n",
        "Numa abordagem usando *Count Vectorizer*, temos o seguinte panorama:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW1dYhAh0NYy"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    'Eu adorei o último jogo do Corinthians. Foi muito melhor que no jogo anterior, com mudanças táticas importantes que impactaram no estilo de jogo do time. ',\n",
        "    'Eu detestei o novo modo de jogo do Call of Duty.'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQWCRlG0dQZ",
        "outputId": "9c25dfad-496c-43ab-c5f1-ef44c1b47328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['adorei' 'anterior' 'call' 'com' 'corinthians' 'de' 'detestei' 'do'\n",
            " 'duty' 'estilo' 'eu' 'foi' 'impactaram' 'importantes' 'jogo' 'melhor'\n",
            " 'modo' 'mudanças' 'muito' 'no' 'novo' 'of' 'que' 'time' 'táticas'\n",
            " 'último']\n",
            "[[1 1 0 1 1 1 0 2 0 1 1 1 1 1 3 1 0 1 1 2 0 0 2 1 1 1]\n",
            " [0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9aWgmUQ06jn"
      },
      "source": [
        "Como todos os termos são igualmente importantes, os classificadores podem entender que o fator mais importante para que uma frase de exemplo possua sentimento positivo é ter mais ocorrências do termo 'jogo'. Usando TF-IDF podemos driblar essa questão ao atribuir um peso menor para termos que ocorrem muito no vocabulário como um todo. Formalmente, temos\n",
        "\n",
        "\n",
        "TF$(p, e)$ = $1 + log\\:f_{p, e}$ [1]\n",
        "\n",
        "IDF$(p, C)$ = $log\\: \\left(1 + \\frac{N}{n_{p}}\\right)$ [2]\n",
        "\n",
        "em que *Term Frequency*, TF, é o termo da equação [1], *Inverse Document Frequency*, IDF, é representado pela equação [2], e ainda $p$ é a palavra em questão, $e$ é o exemplo de texto analisado, $C$ é o corpus, $N$ é o número de documentos no corpus e $n_{p}$ é o número de ocorrências da palavra $p$ em todos os documentos. O resultado final é a multiplicação de TF com IDF, conforme a equação [3]:\n",
        "\n",
        "TF-IDF$(p, e, C)$ = $TF(p, e) * IDF(p, C)$ [3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OudPev3R1FSq"
      },
      "source": [
        "Das frases de exemplo, vamos considerar o termo 'jogo', que foi o que mais apareceu no vocabulário.\n",
        "\n",
        "TF$(jogo, frase 1)$ = $1 + log\\:f_{jogo, frase 1}$\n",
        "$= 1 + log \\:3 = 1 + 0.47712 = 1.47712$  (*Observe que a palavra jogo apareceu 3 vezes na frase 1*)\n",
        "\n",
        "IDF$(jogo, corpus)$ = $log\\: \\left(1 + \\frac{2}{4}\\right)$  (*Observe que a palavra jogo apareceu 4 no corpus. O corpus de exemplo possui dois documentos*)\n",
        "\n",
        ".: Continuando os cálculos temos que IDF$(jogo, corpus)$ = $log\\: \\left(\\frac{6}{4}\\right)$ = $0.17609$\n",
        "\n",
        "\n",
        "\n",
        "TF-IDF$(jogo, frase 1, corpus)$ = $1.47712 * 0.17609$ = $0.2601$\n",
        "\n",
        "Observe que TF da palavra \"jogo\" na frase 1 é um valor alto, pois a palavra jogo aparece 3 vezes nesta sentença, o seu IDF no corpus é baixo $0.17609$. E isso é usado para ponderar esta relação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HFos5R7g4_N"
      },
      "source": [
        "## A seguir veja alguns exemplos de uso do TF-IDF na prática com o auxílio da biblioteca sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHni8RoZ1PFU"
      },
      "source": [
        "sklearn linha 1461 -> https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/feature_extraction/text.py\n",
        "\n",
        "https://towardsdatascience.com/tf-idf-explained-and-python-sklearn-implementation-b020c5e83275\n",
        "\n",
        "https://www.tablesgenerator.com/markdown_tables#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aTrlbFK1MHZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer # chamando a classe TfidfVectorizer biblioteca sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmTu5hlUhKRE"
      },
      "source": [
        "A biblioteca sklearn tem um padrão de uso de suas classes em 3 fases.\n",
        "\n",
        "1) importa a classe desehada;  Exemplo: from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "2) instância a classe desejada; Ex.:vectorizer = TfidfVectorizer()\n",
        "\n",
        "3) chama função fit_transform da classe instanciada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_ISPpvF1Tac",
        "outputId": "5209a7c1-92dd-498c-f0d3-c2b5bc5ef5ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['adorei' 'anterior' 'call' 'com' 'corinthians' 'de' 'detestei' 'do'\n",
            " 'duty' 'estilo' 'eu' 'foi' 'impactaram' 'importantes' 'jogo' 'melhor'\n",
            " 'modo' 'mudanças' 'muito' 'no' 'novo' 'of' 'que' 'time' 'táticas'\n",
            " 'último']\n",
            "[[0.18382334 0.18382334 0.         0.18382334 0.18382334 0.13079182\n",
            "  0.         0.26158365 0.         0.18382334 0.13079182 0.18382334\n",
            "  0.18382334 0.18382334 0.39237547 0.18382334 0.         0.18382334\n",
            "  0.18382334 0.36764669 0.         0.         0.36764669 0.18382334\n",
            "  0.18382334 0.18382334]\n",
            " [0.         0.         0.35300279 0.         0.         0.25116439\n",
            "  0.35300279 0.25116439 0.35300279 0.         0.25116439 0.\n",
            "  0.         0.         0.25116439 0.         0.35300279 0.\n",
            "  0.         0.         0.35300279 0.35300279 0.         0.\n",
            "  0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6Ox_Ivp0urI",
        "outputId": "de2b8234-1457-4890-8647-ddfdc23255b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['adorei', 'anterior', 'call', 'com', 'corinthians', 'de',\n",
              "       'detestei', 'do', 'duty', 'estilo', 'eu', 'foi', 'impactaram',\n",
              "       'importantes', 'jogo', 'melhor', 'modo', 'mudanças', 'muito', 'no',\n",
              "       'novo', 'of', 'que', 'time', 'táticas', 'último'], dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytHd7gVQ1f0s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAuXb3fe1iH3",
        "outputId": "4af45cbc-2118-4a24-c43e-da96bd5e9309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               TF-IDF\n",
            "duty         0.353003\n",
            "detestei     0.353003\n",
            "novo         0.353003\n",
            "of           0.353003\n",
            "modo         0.353003\n",
            "call         0.353003\n",
            "de           0.251164\n",
            "do           0.251164\n",
            "eu           0.251164\n",
            "jogo         0.251164\n",
            "time         0.000000\n",
            "mudanças     0.000000\n",
            "que          0.000000\n",
            "táticas      0.000000\n",
            "no           0.000000\n",
            "muito        0.000000\n",
            "adorei       0.000000\n",
            "importantes  0.000000\n",
            "melhor       0.000000\n",
            "anterior     0.000000\n",
            "impactaram   0.000000\n",
            "foi          0.000000\n",
            "estilo       0.000000\n",
            "corinthians  0.000000\n",
            "com          0.000000\n",
            "último       0.000000\n"
          ]
        }
      ],
      "source": [
        "#Veja os tokens mais relevantes do Exemplo 'Eu detestei o novo modo de jogo do Call of Duty.'\n",
        "df = pd.DataFrame(X[1].T.todense(), index=vectorizer.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
        "df = df.sort_values('TF-IDF', ascending=False)\n",
        "print (df.head(50))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXl7JOSa6IVi"
      },
      "source": [
        "# 3.2 Desafio\n",
        "\n",
        "1. Ajuste o TfidfVectorizer para usar n-grams (bigramas, trigrama etc.) e compare os resultados com a vetorização de unigramas.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

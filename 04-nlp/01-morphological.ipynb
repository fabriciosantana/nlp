{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriciosantana/nlp/blob/main/AKCIT_NLP_M5_Colab_Unidade_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7TmNJgcv6oe"
      },
      "source": [
        "#Identifica√ß√£o\n",
        "\n",
        "Microcurso: Introdu√ß√£o ao Processamento de Linguagem Natural\n",
        "\n",
        "Docente: Dr. Edson Em√≠lio Scalabrin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPQpDH1eXXq-"
      },
      "source": [
        "Atividades\n",
        "\n",
        "üîπ **Atividade 1: Processo de Lematiza√ß√£o**\n",
        "\n",
        "\n",
        "üîπ **Atividade 2: Etiquetagem de Partes do Discurso (POS Tagging)**\n",
        "\n",
        "\n",
        "üîπ **Atividade 3: Processo de Stemming**\n",
        "\n",
        "\n",
        "üîπ **Atividade 4: Compara√ß√£o entre Stemming e Lematiza√ß√£o**\n",
        "\n",
        "üîπ **Atividade 5: Caso de Uso - Classifica√ß√£o de Sentimentos**\n",
        "\n",
        "\n",
        "üîπ **Atividade 6: Algoritmo de Porter para stemming**\n",
        "\n",
        "\n",
        "üîπ **Atividade 7: Indexa√ß√£o de Pequenos Documentos**\n",
        "\n",
        "üîπ **Atividade 8: Redu√ß√£o de Dimensionalidade**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfevqw7Eyf76"
      },
      "source": [
        "### **Objetivos de Aprendizagem**\n",
        "\n",
        "O objetivo √© capacitar o estudante a explorar e aplicar recursos pr√°ticos para realizar an√°lise morfol√≥gica no contexto do Processamento de Linguagem Natural. Este conhecimento ser√° adquirido por meio da execu√ß√£o de pequenos exemplos e exerc√≠cios que destacam a import√¢ncia e a aplica√ß√£o da an√°lise morfol√≥gica em diversas tarefas de processamento de texto.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7kLtOgeMf7F"
      },
      "source": [
        "# **Atividade 1: Processo de Lematiza√ß√£o e sua Import√¢ncia**\n",
        "\n",
        "**Objetivo:** Compreender e aplicar o processo de lematiza√ß√£o.\n",
        "\n",
        "***Tarefa 1.1:*** Utilizar a biblioteca spacy para lematizar um conjunto de palavras fornecidas.\n",
        "\n",
        "**Defini√ß√£o de lemetiza√ß√£o:**\n",
        "\n",
        "A lematiza√ß√£o √© o processo de reduzir palavras √†s suas formas base ou raiz, conhecidas como lemas. Esse processo leva em conta o contexto em que a palavra √© usada, transformando diferentes formas gramaticais em uma √∫nica representa√ß√£o. Isso √© particularmente √∫til em tarefas de processamento de linguagem natural porque ajuda a unificar palavras que t√™m a mesma raiz, mas diferentes formas.\n",
        "\n",
        "**Exemplo:** Vamos considerar as seguintes palavras em portugu√™s: **correndo, correu, correm, muitos, justos**\n",
        "\n",
        "Ao aplicar a lematiza√ß√£o, essas palavras s√£o reduzidas √†s suas formas base: **correndo -> correr, correu -> correr, correm -> correr, muitos -> muito, justos -> justo**\n",
        "\n",
        "**Nota:** Neste exemplo, a biblioteca SpaCy √© utilizada para processar o texto e aplicar a lematiza√ß√£o. As palavras \"correndo\", \"correu\" e \"correm\" s√£o reduzidas ao lema \"correr\", enquanto \"muitos\" e \"justos\" s√£o simplificadas para \"muito\" e \"justo\", respectivamente.\n",
        "\n",
        "A seguir, um pequeno exemplo de como realizar a lematiza√ß√£o em Python usando a biblioteca SpaCy:\n",
        "\n",
        "1.   execute o c√≥digo e analise a sa√≠da; e\n",
        "2.   mude as palavras da linha 24 do c√≥digo Python e re-execute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvZsiZ_9xRbd",
        "outputId": "c18c8de3-905f-4c38-dfb0-3f82e3d92861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['correr', 'correr', 'correr', 'muito', 'justo']\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Fun√ß√£o para instalar pacotes\n",
        "def install_package(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Verificar se SpaCy est√° instalado\n",
        "try:\n",
        "    import spacy\n",
        "except ImportError:\n",
        "    print(\"SpaCy n√£o est√° instalado. Instalando SpaCy...\")\n",
        "    install_package(\"spacy\")\n",
        "\n",
        "# Verificar se o modelo de linguagem em portugu√™s est√° instalado\n",
        "try:\n",
        "    nlp = spacy.load('pt_core_news_sm')\n",
        "except OSError:\n",
        "    print(\"Modelo 'pt_core_news_sm' n√£o encontrado. Baixando o modelo...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"pt_core_news_sm\"])\n",
        "    nlp = spacy.load('pt_core_news_sm')\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"correndo correu correm muitos justos\"\n",
        "\n",
        "# Processar o texto\n",
        "doc = nlp(texto)\n",
        "\n",
        "# Aplicar lematiza√ß√£o\n",
        "palavras_lematizadas = [token.lemma_ for token in doc]\n",
        "\n",
        "print(palavras_lematizadas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqUDujw0F4g0"
      },
      "source": [
        "**Tarefa 1.2:** Tomando como base o conte√∫do lido no ebook, escreva em algumas palavras: a import√¢ncia da lematiza√ß√£o na normaliza√ß√£o de texto e redu√ß√£o de dimensionalidade de vocabul√°rio. Escrever a resposta no espa√ßo indicado a seguir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UVlj8RgOFXk"
      },
      "source": [
        "**Resposta Tarefa 1.2:** (escreva aqui):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtowFCZPrAqB"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWK_Ry8UQoZd"
      },
      "source": [
        "# **Atividade 2: Etiquetagem de Partes do Discurso**\n",
        "\n",
        "**Objetivo:** Compreender os conceitos e utilidades da etiquetagem de partes do discurso (POS tagging).\n",
        "\n",
        "**Tarefa 2.1:** Usar as bibliotecas spaCy (ex. em Portugu√™s) e NLTK (ex. em Ingl√™s) para realizar POS tagging em um texto fornecido.\n",
        "\n",
        "\n",
        "**Defini√ß√£o: Etiquetagem de partes do discurso (ou POS tagging):**\n",
        "\n",
        "Trata-se de uma t√©cnica no processamento de linguagem natural que consiste em atribuir etiquetas gramaticais a cada palavra em um texto. Essas etiquetas identificam a fun√ß√£o gramatical das palavras, como substantivo, verbo, adjetivo, adv√©rbio, entre outros.\n",
        "\n",
        "**Abordagens Baseadas em Regras:**\n",
        "\n",
        "Estas abordagens utilizam um conjunto de regras gramaticais manuais para atribuir etiquetas.\n",
        "\n",
        "**Ferramentas e Bibliotecas:**\n",
        "Diversas ferramentas e bibliotecas de PLN oferecem funcionalidades de POS tagging. Algumas das mais populares incluem:\n",
        "\n",
        "**NLTK (Natural Language Toolkit):** Biblioteca poderosa em Python, oferece etiquetagem de POS junto com muitas outras funcionalidades para PLN.\n",
        "\n",
        "**SpaCy:** Biblioteca em Python otimizada para desempenho e produ√ß√£o, com modelos pr√©-treinados para v√°rias l√≠nguas.\n",
        "\n",
        "**Legenda: Cores e Tags**\n",
        "\n",
        "Substantivos (NN, NNS): White\n",
        "\n",
        "Verbos (VB, VBD, VBZ, etc.): Verde\n",
        "\n",
        "Adjetivos (JJ): Laranja\n",
        "\n",
        "Adv√©rbios (RB): Roxo\n",
        "\n",
        "Determinantes e Preposi√ß√µes (DT, IN): Vermelho\n",
        "\n",
        "\n",
        "**Segue exemplo de C√≥digo com NLTK:**\n",
        "\n",
        "1.   execute o c√≥digo e analise a sa√≠da; e\n",
        "2.   mude as palavras da linha 14 do c√≥digo Python e re-execute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "collapsed": true,
        "id": "AYlxSIH3Q502",
        "outputId": "140be6f8-0e14-43be-bcce-d04c75ee19d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<b><span style='color:red'>The (DT)</span></b> <b><span style='color:white'>cat (NN)</span></b> <b><span style='color:green'>sleeps (VBZ)</span></b> <b><span style='color:red'>on (IN)</span></b> <b><span style='color:red'>the (DT)</span></b> <b><span style='color:white'>porch (NN)</span></b> <b><span style='color:black'>. (.)</span></b>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Fun√ß√£o para instalar pacotes\n",
        "def instalar_pacote(pacote, versao=None):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pacote])\n",
        "\n",
        "# Verificar e instalar NLTK se necess√°rio\n",
        "try:\n",
        "    import nltk\n",
        "except ImportError:\n",
        "    instalar_pacote(\"nltk\")\n",
        "    import nltk\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Baixar o modelo de POS tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')  # add\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')   # add\n",
        "\n",
        "# Texto a ser etiquetado\n",
        "texto = \"The cat sleeps on the porch.\"\n",
        "tokens = word_tokenize(texto)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "# Fun√ß√£o para colorir e formatar texto\n",
        "def format_pos_tags(pos_tags):\n",
        "    formatted_text = []\n",
        "    for word, tag in pos_tags:\n",
        "        color = \"black\"\n",
        "        if tag.startswith('NN'):\n",
        "            color = \"white\"\n",
        "        elif tag.startswith('VB'):\n",
        "            color = \"green\"\n",
        "        elif tag.startswith('JJ'):\n",
        "            color = \"orange\"\n",
        "        elif tag.startswith('RB'):\n",
        "            color = \"purple\"\n",
        "        elif tag.startswith('DT') or tag.startswith('IN'):\n",
        "            color = \"red\"\n",
        "        formatted_text.append(f\"<b><span style='color:{color}'>{word} ({tag})</span></b>\")\n",
        "    return ' '.join(formatted_text)\n",
        "\n",
        "# Formatar e exibir a sa√≠da\n",
        "from IPython.core.display import HTML\n",
        "formatted_text = format_pos_tags(pos_tags)\n",
        "HTML(formatted_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgBeyk354bQW"
      },
      "source": [
        "**Legenda: Cores e Tags (Portugu√™s):**\n",
        "\n",
        "Substantivos (NOUN): white\n",
        "\n",
        "Verbos (VERB): Verde\n",
        "\n",
        "Adjetivos (ADJ): Laranja\n",
        "\n",
        "Adv√©rbios (ADV): Roxo\n",
        "\n",
        "Determinantes e Preposi√ß√µes (DET, ADP): Vermelho\n",
        "\n",
        "\n",
        "\n",
        "**Segue exemplo de C√≥digo com SpaSy.**\n",
        "\n",
        "1.   execute o c√≥digo e analise a sa√≠da; e\n",
        "2.   mude as palavras da linha 23 do c√≥digo Python e re-execute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "S1OM2CH-2m8m",
        "outputId": "a59724c9-1c55-4dad-f16b-db53694b5e97"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<b><span style='color:red'>O (DET)</span></b> <b><span style='color:white'>gato (NOUN)</span></b> <b><span style='color:green'>dorme (VERB)</span></b> <b><span style='color:red'>na (ADP)</span></b> <b><span style='color:white'>varanda (NOUN)</span></b> <b><span style='color:black'>. (PUNCT)</span></b>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Fun√ß√£o para instalar pacotes\n",
        "def instalar_pacote(pacote):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pacote])\n",
        "\n",
        "# Verificar e instalar SpaCy se necess√°rio\n",
        "try:\n",
        "    import spacy\n",
        "except ImportError:\n",
        "    instalar_pacote(\"spacy\")\n",
        "    import spacy\n",
        "\n",
        "# Verificar e instalar o modelo de linguagem para portugu√™s\n",
        "try:\n",
        "    nlp = spacy.load('pt_core_news_sm')\n",
        "except OSError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"pt_core_news_sm\"])\n",
        "    nlp = spacy.load('pt_core_news_sm')\n",
        "\n",
        "# Texto a ser etiquetado\n",
        "texto = \"O gato dorme na varanda.\"\n",
        "\n",
        "doc = nlp(texto)\n",
        "\n",
        "# Fun√ß√£o para colorir e formatar texto\n",
        "def format_pos_tags(doc):\n",
        "    formatted_text = []\n",
        "    for token in doc:\n",
        "        color = \"black\"\n",
        "        if token.pos_ == 'NOUN':\n",
        "            color = \"white\"\n",
        "        elif token.pos_ == 'VERB':\n",
        "            color = \"green\"\n",
        "        elif token.pos_ == 'ADJ':\n",
        "            color = \"orange\"\n",
        "        elif token.pos_ == 'ADV':\n",
        "            color = \"purple\"\n",
        "        elif token.pos_ in ['DET', 'ADP']:\n",
        "            color = \"red\"\n",
        "        formatted_text.append(f\"<b><span style='color:{color}'>{token.text} ({token.pos_})</span></b>\")\n",
        "    return ' '.join(formatted_text)\n",
        "\n",
        "# Formatar e exibir a sa√≠da\n",
        "from IPython.core.display import HTML\n",
        "formatted_text = format_pos_tags(doc)\n",
        "HTML(formatted_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzo6FQArY7eT"
      },
      "source": [
        "**Tarefa 2.2:** Tomando como base o conte√∫do lido no ebook, escreva em algumas palavras a import√¢ncia da etiquetagem de partes do discurso (POS tagging). Escrever a resposta no espa√ßo indicado a seguir.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV5Rx29mZDcL"
      },
      "source": [
        "Resposta Tarefa 2.2: (escreva aqui):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZVpOyuhIRDU"
      },
      "source": [
        "# **Atividade 3: Processo de Stemming**\n",
        "\n",
        "> Adicionar aspas\n",
        "\n",
        "\n",
        "\n",
        "**Objetivo:** Compreender e aplicar o processo de stemming.\n",
        "\n",
        "**Tarefa 3.1:** Utilizar o algoritmo de RSLP para *stemming* em um conjunto de palavras fornecidas.\n",
        "\n",
        "**Defini√ß√£o: Stemming**\n",
        "\n",
        "O stemming √© uma t√©cnica fundamental no Processamento de Linguagem Natural que tem como objetivo reduzir palavras flexionadas ou derivadas ao seu radical ou raiz comum. Essa t√©cnica √© frequentemente utilizada para normalizar texto, reduzir a dimensionalidade do vocabul√°rio e melhorar a efici√™ncia de algoritmos de an√°lise de texto.\n",
        "\n",
        "**Objetivos do Stemming:**\n",
        "\n",
        "\n",
        "*   *Redu√ß√£o do Vocabul√°rio:* Diminuir o n√∫mero de formas de palavras diferentes tratadas pelos modelos de Processamento de Linguagem Natural .\n",
        "\n",
        "*  *Normaliza√ß√£o de Texto:* Unificar diferentes formas de uma palavra para melhorar a consist√™ncia do texto.\n",
        "\n",
        "*   *Melhoria de Desempenho:* Reduzir a carga computacional ao diminuir a diversidade lexical sem perder muito do significado sem√¢ntico.\n",
        "\n",
        "\n",
        "**Algoritmos de Stemming:**\n",
        "\n",
        "\n",
        "1.   *Algoritmo de Porter:* Um dos algoritmos mais populares, desenvolvido por Martin Porter em 1980. Opera atrav√©s de uma s√©rie de regras de reescrita aplicadas sequencialmente. Exemplo: \"correndo\" ‚Üí \"corr\", \"facilmente\" ‚Üí \"facil\".\n",
        "\n",
        "2.   *Algoritmo de Snowball (Porter2):* Uma vers√£o aprimorada do algoritmo de Porter. Oferece maior precis√£o e manipula√ß√£o de exce√ß√µes. Exemplo: \"correu\" ‚Üí \"corr\", \"facilmente\" ‚Üí \"facil\".\n",
        "\n",
        "**Implementa√ß√£o em Python:**\n",
        "A biblioteca NLTK (Natural Language Toolkit) fornece implementa√ß√µes dos algoritmos de stemming, facilitando sua aplica√ß√£o pr√°tica. No entanto, para a l√≠ngua portuguesa, podemos utilizar a biblioteca RSLPStemmer do NLTK, que √© mais adequada para este idioma:\n",
        "\n",
        "1.   execute o c√≥digo e analise a sa√≠da; e\n",
        "2.   mude as palavras das linhas 30 e 50 do c√≥digo Python e re-execute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ2sQA09Iede",
        "outputId": "d77f0e54-2fad-41d8-f5b1-02ac569d31c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stemming em portugu√™s (RSLP): ['corr', 'corr', 'corr', 'facil', 'just']\n",
            "Stemmer Snowball n√£o est√° instalado. Instalando...\n",
            "Stemming em ingl√™s (Snowball): ['run', 'ran', 'run', 'easili', 'fair']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package snowball_data to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Fun√ß√£o para instalar pacotes\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Verificar se o NLTK est√° instalado\n",
        "try:\n",
        "    import nltk\n",
        "except ImportError:\n",
        "    print(\"NLTK n√£o est√° instalado. Instalando...\")\n",
        "    install(\"nltk\")\n",
        "    import nltk\n",
        "\n",
        "# Configurar o diret√≥rio de dados do NLTK no Colab\n",
        "nltk.data.path.append('/root/nltk_data')    # add: linha adicionada\n",
        "\n",
        "# Verificar se o stemmer RSLP est√° instalado\n",
        "try:\n",
        "    nltk.data.find('stemmers/rslp')\n",
        "except LookupError:\n",
        "    print(\"Stemmer RSLP n√£o est√° instalado. Instalando...\")\n",
        "    nltk.download('rslp')\n",
        "\n",
        "# Agora, o c√≥digo para stemmizar as palavras em portugu√™s\n",
        "from nltk.stem import RSLPStemmer\n",
        "\n",
        "# Instanciando o RSLP Stemmer\n",
        "rslp_stemmer = RSLPStemmer()\n",
        "\n",
        "# Lista de palavras em portugu√™s para stemmizar\n",
        "words_pt = ['correndo', 'correu', 'correm', 'facilmente', 'justamente']\n",
        "\n",
        "# Aplicando o RSLP Stemmer\n",
        "stems_rslp = [rslp_stemmer.stem(word) for word in words_pt]\n",
        "print(\"Stemming em portugu√™s (RSLP):\", stems_rslp)\n",
        "\n",
        "# Verificar se o SnowballStemmer est√° instalado\n",
        "try:\n",
        "    nltk.data.find('stemmers/snowball')\n",
        "except LookupError:\n",
        "    print(\"Stemmer Snowball n√£o est√° instalado. Instalando...\")\n",
        "    nltk.download('snowball_data')\n",
        "\n",
        "# Agora, o c√≥digo para stemmizar as palavras em ingl√™s usando Snowball (Porter2)\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "# Instanciando o Snowball Stemmer para ingl√™s\n",
        "snowball_stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "# Lista de palavras em ingl√™s para stemmizar\n",
        "words_en = ['running', 'ran', 'runs', 'easily', 'fairly']\n",
        "\n",
        "# Aplicando o Snowball Stemmer\n",
        "stems_snowball = [snowball_stemmer.stem(word) for word in words_en]\n",
        "print(\"Stemming em ingl√™s (Snowball):\", stems_snowball)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co-4qBu0FdBX"
      },
      "source": [
        "**NOTA:** **Limita√ß√µes do Stemming:**\n",
        "\n",
        "1.  *Redu√ß√£o Excessiva:* Pode resultar em radicais que n√£o s√£o palavras v√°lidas, o que pode afetar a interpreta√ß√£o sem√¢ntica.\n",
        "2.   *Sensibilidade ao Idioma:* Os algoritmos geralmente s√£o projetados para um idioma espec√≠fico e podem n√£o ser eficazes em outros.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkyElKfCZTir"
      },
      "source": [
        "**Tarefa 3.2:** Tomando como base o conte√∫do lido no ebook, escreva em algumas palavras a import√¢ncia o processo de stemming. Escrever a resposta no espa√ßo indicado a seguir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvlNYDyrZeii"
      },
      "source": [
        "Resposta Tarefa 3.2: (escreva aqui):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9c4kfHGS5ig"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CehhyJ_cJBaO"
      },
      "source": [
        "# **Atividade 4: Compara√ß√£o entre Stemming e Lematiza√ß√£o**\n",
        "\n",
        "**Objetivo:** Comparar os processos de stemming e lematiza√ß√£o.\n",
        "\n",
        "**Relembrando as t√©cnias:**\n",
        "\n",
        "**de Lematiza√ß√£o:** A lematiza√ß√£o √© uma t√©cnica de processamento de linguagem natural que transforma palavras flexionadas na sua forma base ou \"lema\", considerando o contexto e as regras lingu√≠sticas. Por exemplo, \"correndo\", \"correu\" e \"correm\" s√£o reduzidos ao lema \"correr\".\n",
        "\n",
        "**de Stemming:** O stemming √© uma t√©cnica que reduz palavras flexionadas ou derivadas ao seu radical ou raiz comum, sem considerar o contexto lingu√≠stico. Por exemplo, \"correndo\", \"correu\" e \"correm\" s√£o reduzidos ao radical \"corr\".\n",
        "\n",
        "\n",
        "**Tarefa 4.1:** Aplicar tanto o stemming quanto a lematiza√ß√£o nas mesmas palavras e comparar os resultados. Para simplificar, segue exemplo de c√≥digo em Python\n",
        "\n",
        "1.   execute o c√≥digo e analise a sa√≠da; e\n",
        "2.   mude as palavras da linha 28 do c√≥digo Python e re-execute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-Dm8iL1JUJE",
        "outputId": "5d0fa490-9037-44d4-e7fa-f08820422253"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palavra             Palavra Lematizada  Palavra_stemmed     \n",
            "------------------------------------------------------------\n",
            "correndo            correr              corr                \n",
            "correu              correr              corr                \n",
            "correm              correr              corr                \n",
            "facilmente          facilmente          facil               \n",
            "justamente          justamente          just                \n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Fun√ß√£o para instalar um pacote se ele n√£o estiver instalado\n",
        "def install_package(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Verificar e instalar o NLTK se necess√°rio (Stemming em Portugu√™s)\n",
        "try:\n",
        "    import nltk\n",
        "except ImportError:\n",
        "    install_package('nltk')\n",
        "    import nltk\n",
        "\n",
        "try:\n",
        "    import spacy\n",
        "except ImportError:\n",
        "    install_package('spacy')\n",
        "    import spacy\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer, RSLPStemmer\n",
        "\n",
        "# Baixar recursos necess√°rios para lematiza√ß√£o e stemming\n",
        "nltk.download('rslp')\n",
        "\n",
        "# Verificar e instalar o modelo de portugu√™s do spaCy\n",
        "try:\n",
        "    nlp = spacy.load(\"pt_core_news_sm\")\n",
        "except Exception:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"pt_core_news_sm\"])\n",
        "    nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "# Inicializar o lematizador e o stemmer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = RSLPStemmer()\n",
        "\n",
        "# Lista de palavras para lematiza√ß√£o e stemming\n",
        "palavras = ['correndo', 'correu', 'correm', 'facilmente', 'justamente']\n",
        "\n",
        "# Lematiza√ß√£o das palavras utilizando o spaCy\n",
        "def lemmatize_word(word):\n",
        "    doc = nlp(word)\n",
        "    # Retorna o lema do primeiro token\n",
        "    return doc[0].lemma_\n",
        "\n",
        "# Lematiza√ß√£o das palavras\n",
        "# Lematiza√ß√£o √© o processo de reduzir uma palavra √† sua forma base ou raiz\n",
        "palavras_lematizadas = [lemmatize_word(palavra) for palavra in palavras]\n",
        "\n",
        "# Stemming das palavras\n",
        "# Stemming √© o processo de reduzir uma palavra ao seu radical\n",
        "palavras_stemmed = [stemmer.stem(palavra) for palavra in palavras]\n",
        "\n",
        "# Compara√ß√£o dos resultados de lematiza√ß√£o e stemming\n",
        "# Cria uma lista de tuplas contendo a palavra original, a palavra lematizada e a palavra ap√≥s stemming\n",
        "comparacao = list(zip(palavras, palavras_lematizadas, palavras_stemmed))\n",
        "\n",
        "# Define o tamanho m√°ximo para cada coluna\n",
        "col_width = 20\n",
        "# Imprime o cabe√ßalho da tabela com espa√ßamento fixo\n",
        "print(f\"{'Palavra':<{col_width}}{'Palavra Lematizada':<{col_width}}{'Palavra_stemmed':<{col_width}}\")\n",
        "print(\"-\" * (col_width * 3))  # Linha separadora\n",
        "\n",
        "# Itera sobre cada tupla e imprime seus valores formatados com espa√ßamento fixo\n",
        "for tupla in comparacao:\n",
        "    print(f\"{tupla[0]:<{col_width}}{tupla[1]:<{col_width}}{tupla[2]:<{col_width}}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_0PkXs9Jhe-"
      },
      "source": [
        "**NOTA: Compara√ß√£o *Stemming* vs. Lematiza√ß√£o:**\n",
        "\n",
        "1.   *Stemming:* Reduz palavras ao seu radical de forma mec√¢nica, sem levar em considera√ß√£o o contexto lingu√≠stico.\n",
        "2.  *Lematiza√ß√£o:* Considera o contexto e transforma as palavras na sua forma base ou lema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxGkuS8FJ5ZP"
      },
      "source": [
        "**Tarefa 4.2:** Escrever no espa√ßo a seguir as suas conclus√µes pr√°ticas sobre a compara√ß√£o em quest√£o."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLc8eoyuPmKc"
      },
      "source": [
        "Resposta Tarefa 4.2: (escreva aqui):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p133rv7KOdt"
      },
      "source": [
        "# **Atividade 5: Casos de Uso - An√°lise de Sentimentos**\n",
        "\n",
        "**Problema: Classifica√ß√£o de Senten√ßas de Acordo com Sentimentos Contexto**\n",
        "\n",
        "No Processamento de Linguagem Natural, uma tarefa comum √© a an√°lise de sentimentos, onde se busca identificar a atitude expressa em um texto. Sentimentos podem ser categorizados como positivos, negativos ou neutros, ajudando a compreender a opini√£o geral sobre um determinado t√≥pico. Esta t√©cnica √© amplamente utilizada em diversas √°reas como an√°lise de mercado, feedback de clientes, monitoramento de redes sociais, entre outras.\n",
        "\n",
        "**Descri√ß√£o do Problema**\n",
        "\n",
        "O problema em quest√£o √© classificar automaticamente senten√ßas em portugu√™s de acordo com seus sentimentos. Precisamos determinar se uma senten√ßa expressa um sentimento positivo, negativo ou neutro.\n",
        "\n",
        "**Objetivo**\n",
        "\n",
        "O objetivo √© criar um sistema automatizado que classifique senten√ßas baseando-se em palavras-chave que indicam sentimentos espec√≠ficos. Esse sistema  deve:\n",
        "\n",
        "\n",
        "1.   Processar senten√ßas em portugu√™s\n",
        "2.   Identificar e lematizar palavras-chave.\n",
        "3.   IClassificar a senten√ßa como \"positivo\", \"negativo\" ou \"neutro\".\n",
        "\n",
        "\n",
        "**Abordagem Utilizada**\n",
        "\n",
        "Para resolver este problema, utilizamos a biblioteca spaCy, que permite o processamento de texto em diversas l√≠nguas, incluindo o portugu√™s. A abordagem consiste em:\n",
        "\n",
        "\n",
        "1.   Carregar o modelo de l√≠ngua portuguesa do spaCy: Utilizamos um modelo pr√©-treinado que inclui regras gramaticais e l√©xicas espec√≠ficas do portugu√™s.\n",
        "2.   Definir uma fun√ß√£o de classifica√ß√£o: Esta fun√ß√£o analisa a senten√ßa e verifica a presen√ßa de palavras-chave lematizadas que indicam sentimentos positivos ou negativos.\n",
        "3.   Classificar exemplos de senten√ßas: Utilizamos a fun√ß√£o para classificar um conjunto de senten√ßas de exemplo e verificar a precis√£o do sistema.\n",
        "\n",
        "**Exemplos Utilizados.**\n",
        "\n",
        "Fornecemos algumas senten√ßas de exemplo para ilustrar como o sistema realiza a classifica√ß√£o:\n",
        "\n",
        "\n",
        "1.   Senten√ßa Positiva: \"Este restaurante √© excelente, adorei a comida!\"\n",
        "2.   Senten√ßa Negativa: \"O atendimento nesta loja √© p√©ssimo, n√£o recomendo.\"\n",
        "3.   Senten√ßa Neutra: \"O filme foi bom, mas o final deixou a desejar.\"\n",
        "4.   Outra Senten√ßa Positiva: \"A viagem foi √≥tima, tudo correu conforme o planejado.\"\n",
        "\n",
        "\n",
        "C√≥digo de Implementa√ß√£o\n",
        "Aqui est√° o c√≥digo que implementa a classifica√ß√£o das senten√ßas:\n",
        "\n",
        "**Classifica√ß√£o de Senten√ßas em Portugu√™s usando spaCy**\n",
        "\n",
        "Neste exemplo, apresentamos como utilizar a biblioteca spaCy para classificar senten√ßas em portugu√™s como \"positivo\", \"negativo\" ou \"neutro\" com base na presen√ßa de palavras-chave. Vamos explorar o c√≥digo passo a passo para entender seu funcionamento.\n",
        "\n",
        "**Fun√ß√£o de Classifica√ß√£o de Senten√ßas**\n",
        "\n",
        "A seguir, definimos uma fun√ß√£o chamada classify_sentence que classifica uma senten√ßa como \"positivo\", \"negativo\" ou \"neutro\" com base nas palavras-chave encontradas na frase:\n",
        "\n",
        "**Tarefa 5.1:** Dado o c√≥digo do caso de uso de classifica√ß√£o de texto em quest√£o:\n",
        "1.   execute o c√≥digo e analise a sa√≠da; e\n",
        "2.   mude as frases das linhas 19 at√© 22 do c√≥digo Python e re-execute.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bn4xEAsazLx",
        "outputId": "780f9fb6-2633-4a17-d20f-ac9d2478b514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Senten√ßa: 'Este restaurante √© excelente, adorei a comida!' - Classifica√ß√£o: positivo\n",
            "Senten√ßa: 'O atendimento nesta loja √© p√©ssimo, n√£o recomendo.' - Classifica√ß√£o: negativo\n",
            "Senten√ßa: 'O filme foi bom, mas o final deixou a desejar.' - Classifica√ß√£o: neutro\n",
            "Senten√ßa: 'A viagem foi √≥tima, tudo correu conforme o planejado.' - Classifica√ß√£o: positivo\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Carregar o modelo em portugu√™s do spaCy\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "\n",
        "# Fun√ß√£o para classificar senten√ßas como \"positivo\" ou \"negativo\"\n",
        "def classify_sentence(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    # Verificar a presen√ßa de palavras-chave\n",
        "    if any(token.lemma_ in ['√≥timo', 'excelente'] for token in doc):\n",
        "        return \"positivo\"\n",
        "    elif any(token.lemma_ in ['ruim', 'p√©ssimo', 'terr√≠vel'] for token in doc):\n",
        "        return \"negativo\"\n",
        "    else:\n",
        "        return \"neutro\"\n",
        "\n",
        "# Exemplos de senten√ßas para classifica√ß√£o\n",
        "sentences = [\n",
        "    \"Este restaurante √© excelente, adorei a comida!\",\n",
        "    \"O atendimento nesta loja √© p√©ssimo, n√£o recomendo.\",\n",
        "    \"O filme foi bom, mas o final deixou a desejar.\",\n",
        "    \"A viagem foi √≥tima, tudo correu conforme o planejado.\"\n",
        "]\n",
        "\n",
        "# Classificar e imprimir os resultados\n",
        "for sentence in sentences:\n",
        "    classification = classify_sentence(sentence)\n",
        "    print(f\"Senten√ßa: '{sentence}' - Classifica√ß√£o: {classification}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKGnTXCjc6pw"
      },
      "source": [
        "**Tarefa 5.2:** Re-escrever o exemplo da Tarefa 5.1 para implementar um pequeno exemplo de an√°lise de sentimentos ampliado, por exemplo, com 20 frases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx872yGxQJ0E"
      },
      "outputs": [],
      "source": [
        "# Incluir c√≥digo fonte da Tarefa 5.2 aqui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4wm1pZHjZ4a5",
        "outputId": "57e28316-6de1-48bf-ced2-afb8c90d5e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pt-core-news-sm==3.7.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.7.0/pt_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from pt-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.2)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4YpnJ5gKSIg"
      },
      "source": [
        "**Atividade 6: Algoritmo de Porter para stemming**\n",
        "\n",
        "**Objetivo:** Explorar algoritmos e t√©cnicas comuns na an√°lise morfol√≥gica.\n",
        "\n",
        "**Como Funciona o Algoritmo de Porter?** O algoritmo de Porter aplica uma s√©rie de regras para transformar palavras em suas ra√≠zes. Aqui est√£o os principais passos:\n",
        "\n",
        "1.   Remo√ß√£o de Sufixos Plurais e de Ger√∫ndio: O algoritmo come√ßa removendo sufixos comuns que indicam pluralidade ou ger√∫ndio. Por exemplo, \"correndo\" pode ser transformado em \"corr\".\n",
        "2.   Tratamento de Sufixos Derivacionais: Em seguida, remove sufixos que s√£o usados para formar novas palavras a partir de outras, como \"mente\" em \"facilmente\". Isso transformaria \"facilmente\" em \"facil\".\n",
        "3.   Simplifica√ß√£o de Palavras: Aplica regras para simplificar palavras, removendo sufixos adicionais e padronizando as formas.\n",
        "4.   Remo√ß√£o de Sufixos Finais: Por fim, remove quaisquer sufixos restantes que possam ser desnecess√°rios para a raiz da palavra.\n",
        "\n",
        "**Tarefa 6.1:** Avaliar a implementa√ß√£o do algoritmo de Porter para stemming a seguir e pata tal:\n",
        "1.   execute o c√≥digo e analise a sa√≠da; e\n",
        "2.   mude a palavra da linha 55 do c√≥digo Python e re-execute.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZD2uv61eQ_X",
        "outputId": "237ee302-eeda-4657-806e-290cb345f6bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palavra original: ['running', 'talked', 'processes', 'organizational']\n",
            "Palavra reduzida (stemming): ['runn', 'talk', 'process', 'organizate']\n"
          ]
        }
      ],
      "source": [
        "def porter_stemmer(word):\n",
        "    \"\"\"\n",
        "    Implementa√ß√£o simplificada do algoritmo de Porter para stemming.\n",
        "    \"\"\"\n",
        "    suffixes = [\n",
        "        ('ational', 'ate'), ('tional', 'tion'), ('enci', 'ence'), ('anci', 'ance'),\n",
        "        ('izer', 'ize'), ('bli', 'ble'), ('alli', 'al'), ('entli', 'ent'),\n",
        "        ('eli', 'e'), ('ousli', 'ous'), ('ization', 'ize'), ('ation', 'ate'),\n",
        "        ('ator', 'ate'), ('alism', 'al'), ('iveness', 'ive'), ('fulness', 'ful'),\n",
        "        ('ousness', 'ous'), ('aliti', 'al'), ('iviti', 'ive'), ('biliti', 'ble'),\n",
        "        ('logi', 'log')\n",
        "    ]\n",
        "\n",
        "    def replace_suffix(word, suffixes):\n",
        "        for suffix, replacement in suffixes:\n",
        "            if word.endswith(suffix):\n",
        "                return word[:-len(suffix)] + replacement\n",
        "        return word\n",
        "\n",
        "    def step_1a(word):\n",
        "        if word.endswith('sses'):\n",
        "            return word[:-2]\n",
        "        elif word.endswith('ies'):\n",
        "            return word[:-2]\n",
        "        elif word.endswith('ss'):\n",
        "            return word\n",
        "        elif word.endswith('s'):\n",
        "            return word[:-1]\n",
        "        return word\n",
        "\n",
        "    def step_1b(word):\n",
        "        if word.endswith('eed'):\n",
        "            return word[:-1] if len(word) > 3 else word\n",
        "        elif word.endswith('ed') and has_vowel(word[:-2]):\n",
        "            return replace_suffix(word[:-2], suffixes)\n",
        "        elif word.endswith('ing') and has_vowel(word[:-3]):\n",
        "            return replace_suffix(word[:-3], suffixes)\n",
        "        return word\n",
        "\n",
        "    def has_vowel(word):\n",
        "        for char in word:\n",
        "            if char in 'aeiou':\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def step_2(word):\n",
        "        return replace_suffix(word, suffixes)\n",
        "\n",
        "    word = step_1a(word)\n",
        "    word = step_1b(word)\n",
        "    word = step_2(word)\n",
        "    return word\n",
        "\n",
        "# Exemplo de uso\n",
        "words = [\"running\", \"talked\", \"processes\", \"organizational\"]\n",
        "stemmed_word = [porter_stemmer(word) for word in words]\n",
        "print(f\"Palavra original: {words}\")\n",
        "print(f\"Palavra reduzida (stemming): {stemmed_word}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQUPiNd3brh5",
        "outputId": "fa43bea1-1065-4b8c-f2eb-519f28beec42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "punkt  punkt_tab  punkt_tab.zip  punkt.zip\n"
          ]
        }
      ],
      "source": [
        "!ls /root/nltk_data/tokenizers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb3PqIUfU1uP"
      },
      "source": [
        "**Tarefa 6.2:** Re-escrever o exemplo da Tarefa 6.1 para implementar um pequeno exemplo para operar com frases em portugu√™s. Insira  o c√≥digo no espa√ßo a seguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTUoNk0-VJE7"
      },
      "outputs": [],
      "source": [
        "# Incluir c√≥digo fonte da Tarefa 6.2 aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIZolDyRTYr2"
      },
      "source": [
        "# **Atividade 7: Problema de Indexa√ß√£o de pequenos documentos**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxpS3KIQZXMM"
      },
      "source": [
        "\n",
        "##**Indexa√ß√£o usando a abordagem TF-IDF**\n",
        "\n",
        "No campo do Processamento de Linguagem Natural e da Recupera√ß√£o de Informa√ß√£o, o problema de indexa√ß√£o de documentos √© crucial para organizar e recuperar informa√ß√µes de grandes volumes de texto de forma eficiente. Um m√©todo amplamente utilizado para esse fim √© o TF-IDF, que significa \"Term Frequency-Inverse Document Frequency\". Este m√©todo ajuda a medir a import√¢ncia de uma palavra em um documento dentro de uma cole√ß√£o ou corpus de documentos.\n",
        "\n",
        "## Cen√°rio\n",
        "\n",
        "Imagine que voc√™ tem uma grande cole√ß√£o de documentos, como artigos cient√≠ficos, posts de blogs, ou p√°ginas da web. Quando um usu√°rio faz uma consulta de busca, o sistema precisa rapidamente identificar quais documentos s√£o mais relevantes para essa consulta. O problema de indexa√ß√£o de documentos √©, portanto, criar uma estrutura que permita essa recupera√ß√£o eficiente e precisa de informa√ß√µes.\n",
        "\n",
        "\n",
        "## O Que √© TF-IDF?\n",
        "\n",
        "TF-IDF √© uma m√©trica que ajuda a avaliar a import√¢ncia de uma palavra em um documento, levando em conta tanto a frequ√™ncia da palavra no documento (TF) quanto a frequ√™ncia dessa palavra em todo o corpus de documentos (IDF). Vamos entender cada componente:\n",
        "\n",
        "\n",
        "### TF (Term Frequency)\n",
        "\n",
        "Frequ√™ncia do termo no documento. Calcula-se quantas vezes uma palavra aparece em um documento em rela√ß√£o ao n√∫mero total de palavras nesse documento. A f√≥rmula √©:\n",
        "\n",
        "$$\n",
        "\\text{TF}(t, d) = \\frac{f_{t,d}}{N_d}\n",
        "$$\n",
        "\n",
        "- $(f_{t,d})$  √© a contagem de ocorr√™ncias do termo \\( t \\) no documento \\( d \\)\n",
        "- $(N_d)$ √©  o n√∫mero total de termos no documento \\( d \\)\n",
        "\n",
        "\n",
        "### IDF (Inverse Document Frequency)\n",
        "\n",
        "Frequ√™ncia inversa do documento. Avalia a import√¢ncia do termo no corpus inteiro, penalizando termos comuns em muitos documentos. A f√≥rmula √©:\n",
        "\n",
        "$$\n",
        "\\text{IDF}(t, D) = \\log \\left( \\frac{N}{|d \\in D: t \\in d|} \\right)\n",
        "$$\n",
        "\n",
        "- $( N )$ √© o n√∫mero total de documentos no corpus\n",
        "- $( |d \\in D: t \\in d| )\\$ √© o n√∫mero de documentos onde o termo \\( t \\) aparece\n",
        "\n",
        "\n",
        "### TF-IDF\n",
        "\n",
        "Produto do TF e IDF. Combina ambas as m√©tricas para calcular a import√¢ncia do termo no documento, ajustada pela frequ√™ncia no corpus. A f√≥rmula √©:\n",
        "\n",
        "$$\n",
        "\\text{TF-IDF}(t, d, D) = \\text{TF}(t, d) \\times \\text{IDF}(t, D)\n",
        "$$\n",
        "\n",
        "## Como o TF-IDF Resolve o Problema de Indexa√ß√£o\n",
        "\n",
        "- **Relev√¢ncia de Termos**: TF-IDF ajuda a identificar palavras importantes para um documento espec√≠fico, reduzindo a influ√™ncia de termos comuns e irrelevantes.\n",
        "- **Ranking de Documentos**: Quando uma busca de documento √© feita, o sistema pode calcular o TF-IDF de cada termo da consulta em cada documento e somar esses valores para determinar quais documentos s√£o mais relevantes.\n",
        "- **Efici√™ncia na Busca**: Utilizando estruturas como matrizes esparsas, os sistemas podem rapidamente calcular e comparar valores de TF-IDF, permitindo uma recupera√ß√£o eficiente de documentos relevantes.\n",
        "\n",
        "## Exemplo Pr√°tico\n",
        "\n",
        "Considere o seguinte corpus com cinco documentos:\n",
        "\n",
        "- Documento 1: \"O gato est√° correndo no jardim.\"\n",
        "- Documento 2: \"Os gatos gostam de correr e brincar.\"\n",
        "- Documento 3: \"Ela gosta de estudar lingu√≠stica computacional.\"\n",
        "- Documento 4: \"Lingu√≠stica computacional √© uma √°rea fascinante.\"\n",
        "- Documento 5: \"O gado preto da Renata dorme na varanda.\"\n",
        "\n",
        "Vamos calcular o TF-IDF para a palavra \"gosta\".\n",
        "\n",
        "### TF (Term Frequency)\n",
        "\n",
        "- Documento 1: \"gosta\" n√£o aparece (TF = 0)\n",
        "- Documento 2: \"gosta\" aparece uma vez em 6 palavras (TF = 1/6 ‚âà 0.167)\n",
        "- Documento 3: \"gosta\" aparece uma vez em 6 palavras (TF = 1/6 ‚âà 0.167)\n",
        "- Documento 4: \"gosta\" n√£o aparece (TF = 0)\n",
        "- Documento 5: \"gosta\" n√£o aparece (TF = 0)\n",
        "\n",
        "### IDF (Inverse Document Frequency)\n",
        "\n",
        "- \"gosta\" aparece em 2 dos 5 documentos.\n",
        "- IDF = $$ \\log \\left( \\frac{5}{2} \\right) \\approx 0.398 $$\n",
        "\n",
        "### TF-IDF\n",
        "\n",
        "- Documento 1: 0 * 0.398 = 0\n",
        "- Documento 2: 0.167 * 0.398 ‚âà 0.066\n",
        "- Documento 3: 0.167 * 0.398 ‚âà 0.066\n",
        "- Documento 4: 0 * 0.398 = 0\n",
        "- Documento 5: 0 * 0.398 = 0\n",
        "\n",
        "### C√°lculo da Similaridade usando o Coeficiente do Cosseno\n",
        "\n",
        "A similaridade entre dois documentos pode ser calculada usando o coeficiente do cosseno, que mede o √¢ngulo entre dois vetores. A f√≥rmula para calcular a similaridade do cosseno entre dois vetores \\($\\mathbf{A} $\\) e \\($\\mathbf{B}$\\) √©:\n",
        "\n",
        "$$\n",
        "\\text{similaridade}_{\\cos}(\\mathbf{A}, \\mathbf{B}) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\|\\mathbf{B}\\|}\n",
        "$$\n",
        "\n",
        "onde:\n",
        "\n",
        "- \\( $\\mathbf{A} \\cdot \\mathbf{B} $\\) √© o produto escalar dos vetores \\( $\\mathbf{A}$ \\) e \\( $\\mathbf{B}$ \\)\n",
        "- \\( $\\|\\mathbf{A}\\|$ \\) √© a norma (magnitude) do vetor \\( $\\mathbf{A} $\\)\n",
        "- \\( $\\|\\mathbf{B}\\|$ \\) √© a norma (magnitude) do vetor \\( $\\mathbf{B} $\\)\n",
        "\n",
        "\n",
        "\n",
        "### Exemplo de C√°lculo da Similaridade do Cosseno\n",
        "\n",
        "Vamos calcular a similaridade do cosseno entre os Documentos 2 e 3 usando seus vetores TF-IDF simplificados. Suponha que temos os seguintes vetores TF-IDF para simplifica√ß√£o:\n",
        "\n",
        "\n",
        "-\\($\\mathbf{A} = [0.066, 0, 0, 0, 0]$\\) (Documento 2)\n",
        "-\\($\\mathbf{B} = [0.066, 0, 0, 0, 0]$\\) (Documento 3)\n",
        "\n",
        "\n",
        "A similaridade do cosseno √© calculada como:\n",
        "\n",
        "$\n",
        "\\text{similaridade}_{\\cos}(\\mathbf{A}, \\mathbf{B}) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\|\\mathbf{B}\\|} = \\frac{0.066 \\times 0.066}{\\sqrt{0.066^2} \\times \\sqrt{0.066^2}} = \\frac{0.004356}{0.066 \\times 0.066} = 1$\n",
        "\n",
        "Neste caso, a similaridade do cosseno entre os Documentos 2 e 3 √© 1, indicando que eles s√£o id√™nticos em termos de conte√∫do de TF-IDF.\n",
        "\n",
        "### Resultados\n",
        "\n",
        "A import√¢ncia da palavra \"gosta\" √© maior nos Documentos 2 e 3, ambos com um valor TF-IDF de aproximadamente 0.066. Os Documentos 1, 4 e 5 t√™m um valor TF-IDF de 0 para \"gosta\", indicando que a palavra n√£o aparece nesses documentos.\n",
        "\n",
        "### **Tarefa 7.1:** Avaliar a implementa√ß√£o do sistema de indexa√ß√£o de documentos baseado no TFIDF a seguir e pata tal:\n",
        "1.   execute o c√≥digo e analise a sa√≠da; e\n",
        "2.   inclua mais algumas frases linhas 68-72 e re-execute mudando os termos da  consulta linhas 114 e 115.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7VoEXMlTdav",
        "outputId": "77d64b1e-d9f8-498b-c034-ddcc4e18839d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Documentos Preprocessados:\n",
            "o gat est corr em o jardim .\n",
            "o gat gost de corr e brinc .\n",
            "ela gost de estud lingu√≠s computac .\n",
            "lingu√≠s computac ser um √°re fascin .\n",
            "o gat pret de o renat dorm em o varand .\n",
            "Matriz TF-IDF:\n",
            "      brinc  computac      corr        de      dorm       ela        em  \\\n",
            "0  0.000000  0.000000  0.416607  0.000000  0.000000  0.000000  0.416607   \n",
            "1  0.559117  0.000000  0.451092  0.374447  0.000000  0.000000  0.000000   \n",
            "2  0.000000  0.384569  0.000000  0.319227  0.000000  0.476663  0.000000   \n",
            "3  0.000000  0.350388  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "4  0.000000  0.000000  0.000000  0.284329  0.424555  0.000000  0.342528   \n",
            "\n",
            "        est     estud    fascin       gat      gost    jardim   lingu√≠s  \\\n",
            "0  0.516374  0.000000  0.000000  0.345822  0.000000  0.516374  0.000000   \n",
            "1  0.000000  0.000000  0.000000  0.374447  0.451092  0.000000  0.000000   \n",
            "2  0.000000  0.476663  0.000000  0.000000  0.384569  0.000000  0.384569   \n",
            "3  0.000000  0.000000  0.434297  0.000000  0.000000  0.000000  0.350388   \n",
            "4  0.000000  0.000000  0.000000  0.284329  0.000000  0.000000  0.000000   \n",
            "\n",
            "       pret     renat       ser        um    varand       √°re  \n",
            "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "3  0.000000  0.000000  0.434297  0.434297  0.000000  0.434297  \n",
            "4  0.424555  0.424555  0.000000  0.000000  0.424555  0.000000  \n",
            "Consulta: 'gato no jardim'\n",
            "Documento mais similar: O gato est√° correndo no jardim.\n",
            "Similaridades: [[0.74819537 0.17307225 0.         0.         0.32214456]]\n",
            "\n",
            "Consulta: 'estudar lingu√≠stica'\n",
            "Documento mais similar: Ela gosta de estudar lingu√≠stica computacional.\n",
            "Similaridades: [[0.         0.         0.61245459 0.22001359 0.        ]]\n",
            "\n",
            "Consulta: 'gato da Renata'\n",
            "Documento mais similar: O gato preto da Renata dorme na varanda.\n",
            "Similaridades: [[0.16815247 0.36414246 0.15522094 0.         0.58475075]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Etapa 1: Verifica√ß√£o e Instala√ß√£o das Bibliotecas Necess√°rias\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_and_import(package):\n",
        "    try:\n",
        "        __import__(package)\n",
        "    except ImportError:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Instalar as bibliotecas necess√°rias\n",
        "install_and_import('spacy')\n",
        "install_and_import('nltk')\n",
        "install_and_import('scikit-learn')\n",
        "install_and_import('pandas')\n",
        "\n",
        "# Baixar o modelo de portugu√™s do spaCy, caso n√£o esteja instalado\n",
        "subprocess.run([sys.executable, \"-m\", \"spacy\", \"download\", \"pt_core_news_sm\"])\n",
        "\n",
        "# Etapa 2: Importar as Bibliotecas e Inicializar Recursos\n",
        "import spacy\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# Baixar recursos necess√°rios do nltk para stemming e lematiza√ß√£o\n",
        "nltk.download('rslp')  # Baixar o stemmer RSLP para portugu√™s\n",
        "nltk.download('wordnet')  # Baixar o WordNet para lematiza√ß√£o\n",
        "nltk.download('omw-1.4')  # Baixar o Open Multilingual Wordnet\n",
        "nltk.download('punkt')  # Baixar o tokenizer 'punkt' para portugu√™s\n",
        "\n",
        "from nltk.stem import RSLPStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Carregar o modelo de portugu√™s do spaCy\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "# Inicializar o lematizador e o stemmer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = RSLPStemmer()\n",
        "\n",
        "# Etapa 3: Definir Fun√ß√µes de Pr√©-Processamento\n",
        "\n",
        "# Fun√ß√£o de lematiza√ß√£o usando spaCy\n",
        "# Esta fun√ß√£o utiliza o spaCy para lematizar o texto, retornando os lemas dos tokens.\n",
        "def lematizar(texto):\n",
        "    doc = nlp(texto)\n",
        "    return ' '.join([token.lemma_ for token in doc])\n",
        "\n",
        "# Fun√ß√£o de stemming usando NLTK\n",
        "# Esta fun√ß√£o utiliza o nltk para aplicar stemming aos tokens do texto.\n",
        "def aplicar_stemming(texto):\n",
        "    tokens = nltk.word_tokenize(texto, language='portuguese')\n",
        "    return ' '.join([stemmer.stem(token) for token in tokens])\n",
        "\n",
        "# Fun√ß√£o de pr√©-processamento completo\n",
        "# Esta fun√ß√£o aplica lematiza√ß√£o seguida de stemming ao texto.\n",
        "def preprocessamento(texto):\n",
        "    texto_lematizado = lematizar(texto)\n",
        "    texto_stemmed = aplicar_stemming(texto_lematizado)\n",
        "    return texto_stemmed\n",
        "\n",
        "# Etapa 4: Pr√©-Processar Documentos e Calcular TF-IDF\n",
        "\n",
        "# Lista de documentos de exemplo para indexa√ß√£o\n",
        "documentos = [\n",
        "    \"O gato est√° correndo no jardim.\",\n",
        "    \"Os gatos gostam de correr e brincar.\",\n",
        "    \"Ela gosta de estudar lingu√≠stica computacional.\",\n",
        "    \"Lingu√≠stica computacional √© uma √°rea fascinante.\",\n",
        "    \"O gato preto da Renata dorme na varanda.\"\n",
        "]\n",
        "\n",
        "# Aplicar pr√©-processamento em todos os documentos\n",
        "# Esta linha aplica a fun√ß√£o de pr√©-processamento em cada documento.\n",
        "documentos_preprocessados = [preprocessamento(doc) for doc in documentos]\n",
        "\n",
        "# Exibir os documentos preprocessados\n",
        "print(\"Documentos Preprocessados:\")\n",
        "for doc in documentos_preprocessados:\n",
        "    print(doc)\n",
        "\n",
        "# Inicializar o vetor TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Ajustar e transformar os documentos preprocessados\n",
        "# Esta linha ajusta e transforma os documentos preprocessados em uma matriz TF-IDF.\n",
        "tfidf_matrix = vectorizer.fit_transform(documentos_preprocessados)\n",
        "\n",
        "# Obter os termos (features) do TF-IDF\n",
        "termos = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Exibir a matriz TF-IDF usando um DataFrame para melhor visualiza√ß√£o\n",
        "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=termos)\n",
        "\n",
        "# Exibir a matriz TF-IDF\n",
        "print(\"Matriz TF-IDF:\")\n",
        "print(df_tfidf)\n",
        "\n",
        "# Etapa 5: Consulta de Documentos e Calcular Similaridade\n",
        "\n",
        "# Fun√ß√£o para processar consulta e calcular similaridade\n",
        "# Esta fun√ß√£o pr√©-processa a consulta, transforma em vetor TF-IDF e\n",
        "# calcula a similaridade coseno.\n",
        "def consultar_documentos(consulta):\n",
        "    consulta_preprocessada = preprocessamento(consulta)\n",
        "    consulta_tfidf = vectorizer.transform([consulta_preprocessada])\n",
        "    similaridades = cosine_similarity(consulta_tfidf, tfidf_matrix)\n",
        "    documento_mais_similar = similaridades.argmax()\n",
        "    return documento_mais_similar, similaridades\n",
        "\n",
        "# Exemplo de consultas\n",
        "consultas = [\n",
        "    \"gato no jardim\",\n",
        "    \"estudar lingu√≠stica\",\n",
        "    \"gato da Renata\"\n",
        "]\n",
        "\n",
        "# Processar cada consulta e exibir resultados\n",
        "for consulta in consultas:\n",
        "    indice, similaridades = consultar_documentos(consulta)\n",
        "    print(f\"Consulta: '{consulta}'\")\n",
        "    print(f\"Documento mais similar: {documentos[indice]}\")\n",
        "    print(f\"Similaridades: {similaridades}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8tJ-GVil8LD"
      },
      "source": [
        "**Tarefa 7.2:** Incrementar a base de documentos com texto de assuntos diferentes; e analisar o efeito do incremento de documentos quanto ao tamanho do vetor de termos e a precis√£o dos resultados das consultas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWlrOp-UmJj8"
      },
      "outputs": [],
      "source": [
        "# incluir a c√≥digo referente a Tarefa 7.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPuKZ3Zs7Qnf"
      },
      "source": [
        "# **Atividade 8: Processamento e An√°lise de Texto em Portugu√™s - Redu√ß√£o de dimensionalidade**\n",
        "\n",
        "#### Objetivo:\n",
        "Nesta atividade de laborat√≥rio, voc√™ aprender√° a implementar um pipeline de processamento de linguagem natural (PLN) para textos em portugu√™s. Especificamente, voc√™ realizar√° as etapas de instala√ß√£o de bibliotecas, tokeniza√ß√£o, remo√ß√£o de stopwords, lematiza√ß√£o, e an√°lise de frequ√™ncia de palavras, usando a linguagem Python e as bibliotecas `nltk` e `spaCy`.\n",
        "\n",
        "### 8.1: Atividade: Execute c√≥digo a seguir e An√°lise de Resultados\n",
        "\n",
        "#### Passos da Atividade:\n",
        "\n",
        "**Etapa 1: Verifica√ß√£o e Instala√ß√£o das Bibliotecas Necess√°rias**\n",
        "   - Ser√° utilizada uma fun√ß√£o em Python para verificar se as bibliotecas necess√°rias (`nltk`, `spacy`) est√£o instaladas no ambiente. Caso contr√°rio, elas ser√£o instaladas automaticamente.\n",
        "   - O modelo de linguagem do spaCy para portugu√™s (`pt_core_news_sm`) ser√° baixado e carregado para o uso nas etapas subsequentes.\n",
        "\n",
        "**Etapa 2: Prepara√ß√£o e Limpeza do Texto**\n",
        "   - Um conjunto de frases em portugu√™s ser√° processado. As frases incluem diversos contextos em que o verbo \"correr\" √© utilizado em diferentes formas verbais.\n",
        "   - A primeira tarefa ser√° substituir pontua√ß√µes e n√∫meros por espa√ßos, facilitando a tokeniza√ß√£o subsequente.\n",
        "\n",
        "**Etapa 3: Tokeniza√ß√£o**\n",
        "   - As frases ser√£o divididas em tokens individuais (palavras), utilizando a fun√ß√£o `word_tokenize` da biblioteca `nltk`.\n",
        "   - A tokeniza√ß√£o √© uma etapa essencial no pr√©-processamento de texto, pois divide o texto em unidades que podem ser processadas individualmente.\n",
        "\n",
        "**Etapa 4: Remo√ß√£o de Stopwords**\n",
        "   - Stopwords (palavras muito comuns como \"o\", \"e\", \"a\") ser√£o removidas do texto tokenizado. Isso √© feito para focar no processamento de palavras mais relevantes para a an√°lise.\n",
        "\n",
        "**Etapa 5: Lematiza√ß√£o**\n",
        "   - Os tokens restantes ser√£o lematizados, ou seja, reduzidos √† sua forma base (lema). Neste exemplo, o foco √© lematizar diversas formas do verbo \"correr\" (\"corri\", \"correndo\", \"correu\", etc.) para o lema \"correr\".\n",
        "   - A lematiza√ß√£o manual ser√° aplicada para garantir que certas formas verbais e substantivas sejam corretamente lematizadas. A lematiza√ß√£o √© aplicada manualmente, pois \"corri\" e \"corrida\" n√£o √© capturada como pertencente ao lema \"correr\".\n",
        "\n",
        "**Etapa 6: An√°lise de Frequ√™ncia**\n",
        "   - Ap√≥s a lematiza√ß√£o, a frequ√™ncia das palavras de interesse (incluindo suas formas lematizadas) ser√° calculada e exibida.\n",
        "   - Esta etapa permite uma an√°lise quantitativa de quantas vezes determinadas palavras aparecem no conjunto de textos, antes e depois da lematiza√ß√£o.\n",
        "\n",
        "**Etapa 7: Conclus√£o**\n",
        "   - A etapa final da atividade envolve a verifica√ß√£o da **redu√ß√£o da dimensionalidade** do texto como resultado da aplica√ß√£o da lematiza√ß√£o.\n",
        "   - Redu√ß√£o da dimensionalidade se refere √† diminui√ß√£o do n√∫mero de palavras distintas no texto ap√≥s a lematiza√ß√£o, o que simplifica a an√°lise e modelagem de dados lingu√≠sticos.\n",
        "   - Voc√™ ir√° comparar a quantidade de palavras antes e depois da lematiza√ß√£o para observar como diferentes formas verbais foram unificadas em lemas √∫nicos, reduzindo a complexidade do vocabul√°rio.\n",
        "\n",
        "#### Objetivo Educacional:\n",
        "Ao concluir esta atividade, voc√™ ter√° uma compreens√£o pr√°tica de como processar textos em portugu√™s para an√°lise lingu√≠stica, incluindo etapas essenciais como tokeniza√ß√£o, remo√ß√£o de stopwords, lematiza√ß√£o e an√°lise de frequ√™ncia. A verifica√ß√£o da redu√ß√£o da dimensionalidade do texto ap√≥s a lematiza√ß√£o ir√° demonstrar a efici√™ncia dessa t√©cnica em simplificar o vocabul√°rio e facilitar an√°lises posteriores, como categoriza√ß√£o de texto ou an√°lise de sentimentos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RbZxbdfR7SYW",
        "outputId": "4c257aa7-1180-4c93-f135-6f3a876990a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens ap√≥s remo√ß√£o de stopwords: [880] ['ontem', 'corri', 'cinco', 'quil√¥metros', 'parque', 'cachorro', 'come√ßou', 'latir', 'rapidamente', 'corri', 'casa', 'corri', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvi', 'not√≠cia', 'corri', 'contar', 'amigos', 'escola', 'corri', 'parque', 'encontrar', 'amigos', 'ontem', 'corri', 'cinco', 'quil√¥metros', 'parque', 'cachorro', 'come√ßou', 'latir', 'rapidamente', 'corri', 'casa', 'corri', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvi', 'not√≠cia', 'corri', 'contar', 'amigos', 'escola', 'corri', 'parque', 'encontrar', 'amigos', 'ontem', 'corri', 'cinco', 'quil√¥metros', 'parque', 'cachorro', 'come√ßou', 'latir', 'rapidamente', 'corri', 'casa', 'corri', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvi', 'not√≠cia', 'corri', 'contar', 'amigos', 'escola', 'corri', 'parque', 'encontrar', 'amigos', 'ontem', 'corri', 'cinco', 'quil√¥metros', 'parque', 'cachorro', 'come√ßou', 'latir', 'rapidamente', 'corri', 'casa', 'corri', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvi', 'not√≠cia', 'corri', 'contar', 'amigos', 'escola', 'corri', 'parque', 'encontrar', 'amigos', 'ontem', 'corri', 'cinco', 'quil√¥metros', 'parque', 'cachorro', 'come√ßou', 'latir', 'rapidamente', 'corri', 'casa', 'corri', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvi', 'not√≠cia', 'corri', 'contar', 'amigos', 'escola', 'corri', 'parque', 'encontrar', 'amigos', 'ontem', 'corri', 'cinco', 'quil√¥metros', 'parque', 'cachorro', 'come√ßou', 'latir', 'rapidamente', 'corri', 'casa', 'corri', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvi', 'not√≠cia', 'corri', 'contar', 'amigos', 'escola', 'corri', 'parque', 'encontrar', 'amigos', 'ontem', 'corri', 'cinco', 'quil√¥metros', 'parque', 'cachorro', 'come√ßou', 'latir', 'rapidamente', 'corri', 'casa', 'corri', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvi', 'not√≠cia', 'corri', 'contar', 'amigos', 'escola', 'corri', 'parque', 'encontrar', 'amigos', 'ontem', 'corri', 'cinco', 'quil√¥metros', 'parque', 'cachorro', 'come√ßou', 'latir', 'rapidamente', 'corri', 'casa', 'corri', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvi', 'not√≠cia', 'corri', 'contar', 'amigos', 'escola', 'corri', 'parque', 'encontrar', 'amigos', 'ontem', 'corri', 'cinco', 'quil√¥metros', 'parque', 'cachorro', 'come√ßou', 'latir', 'rapidamente', 'corri', 'casa', 'corri', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvi', 'not√≠cia', 'corri', 'contar', 'amigos', 'escola', 'corri', 'parque', 'encontrar', 'amigos', 'ontem', 'corri', 'cinco', 'quil√¥metros', 'parque', 'cachorro', 'come√ßou', 'latir', 'rapidamente', 'corri', 'casa', 'corri', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvi', 'not√≠cia', 'corri', 'contar', 'amigos', 'escola', 'corri', 'parque', 'encontrar', 'amigos', 'correndo', 'pegar', '√¥nibus', 'atletas', 'correndo', 'volta', 'pista', 'vi', 'grupo', 'pessoas', 'correndo', 'parque', 'crian√ßas', 'correndo', 'brincando', 'jardim', 'cachorro', 'correndo', 'atr√°s', 'bola', 'correndo', 'pegar', '√¥nibus', 'atletas', 'correndo', 'volta', 'pista', 'vi', 'grupo', 'pessoas', 'correndo', 'parque', 'crian√ßas', 'correndo', 'brincando', 'jardim', 'cachorro', 'correndo', 'atr√°s', 'bola', 'correndo', 'pegar', '√¥nibus', 'atletas', 'correndo', 'volta', 'pista', 'vi', 'grupo', 'pessoas', 'correndo', 'parque', 'crian√ßas', 'correndo', 'brincando', 'jardim', 'cachorro', 'correndo', 'atr√°s', 'bola', 'correndo', 'pegar', '√¥nibus', 'atletas', 'correndo', 'volta', 'pista', 'vi', 'grupo', 'pessoas', 'correndo', 'parque', 'crian√ßas', 'correndo', 'brincando', 'jardim', 'cachorro', 'correndo', 'atr√°s', 'bola', 'correndo', 'pegar', '√¥nibus', 'atletas', 'correndo', 'volta', 'pista', 'vi', 'grupo', 'pessoas', 'correndo', 'parque', 'crian√ßas', 'correndo', 'brincando', 'jardim', 'cachorro', 'correndo', 'atr√°s', 'bola', 'correndo', 'pegar', '√¥nibus', 'atletas', 'correndo', 'volta', 'pista', 'vi', 'grupo', 'pessoas', 'correndo', 'parque', 'crian√ßas', 'correndo', 'brincando', 'jardim', 'cachorro', 'correndo', 'atr√°s', 'bola', 'correndo', 'pegar', '√¥nibus', 'atletas', 'correndo', 'volta', 'pista', 'vi', 'grupo', 'pessoas', 'correndo', 'parque', 'crian√ßas', 'correndo', 'brincando', 'jardim', 'cachorro', 'correndo', 'atr√°s', 'bola', 'correndo', 'pegar', '√¥nibus', 'atletas', 'correndo', 'volta', 'pista', 'vi', 'grupo', 'pessoas', 'correndo', 'parque', 'crian√ßas', 'correndo', 'brincando', 'jardim', 'cachorro', 'correndo', 'atr√°s', 'bola', 'correndo', 'pegar', '√¥nibus', 'atletas', 'correndo', 'volta', 'pista', 'vi', 'grupo', 'pessoas', 'correndo', 'parque', 'crian√ßas', 'correndo', 'brincando', 'jardim', 'cachorro', 'correndo', 'atr√°s', 'bola', 'correr√£o', 'maratona', 'pr√≥ximo', 'm√™s', 'competidores', 'correr√£o', 'diferentes', 'categorias', 'todos', 'atletas', 'correr√£o', 'tempo', 'correr√£o', 'primeira', 'vez', 'prova', 'corredores', 'profissionais', 'correr√£o', 'pr√≥xima', 'competi√ß√£o', 'correr√£o', 'maratona', 'pr√≥ximo', 'm√™s', 'competidores', 'correr√£o', 'diferentes', 'categorias', 'todos', 'atletas', 'correr√£o', 'tempo', 'correr√£o', 'primeira', 'vez', 'prova', 'corredores', 'profissionais', 'correr√£o', 'pr√≥xima', 'competi√ß√£o', 'correr√£o', 'maratona', 'pr√≥ximo', 'm√™s', 'competidores', 'correr√£o', 'diferentes', 'categorias', 'todos', 'atletas', 'correr√£o', 'tempo', 'correr√£o', 'primeira', 'vez', 'prova', 'corredores', 'profissionais', 'correr√£o', 'pr√≥xima', 'competi√ß√£o', 'correr√£o', 'maratona', 'pr√≥ximo', 'm√™s', 'competidores', 'correr√£o', 'diferentes', 'categorias', 'todos', 'atletas', 'correr√£o', 'tempo', 'correr√£o', 'primeira', 'vez', 'prova', 'corredores', 'profissionais', 'correr√£o', 'pr√≥xima', 'competi√ß√£o', 'correr√£o', 'maratona', 'pr√≥ximo', 'm√™s', 'competidores', 'correr√£o', 'diferentes', 'categorias', 'todos', 'atletas', 'correr√£o', 'tempo', 'correr√£o', 'primeira', 'vez', 'prova', 'corredores', 'profissionais', 'correr√£o', 'pr√≥xima', 'competi√ß√£o', 'correr√£o', 'maratona', 'pr√≥ximo', 'm√™s', 'competidores', 'correr√£o', 'diferentes', 'categorias', 'todos', 'atletas', 'correr√£o', 'tempo', 'correr√£o', 'primeira', 'vez', 'prova', 'corredores', 'profissionais', 'correr√£o', 'pr√≥xima', 'competi√ß√£o', 'correr√£o', 'maratona', 'pr√≥ximo', 'm√™s', 'competidores', 'correr√£o', 'diferentes', 'categorias', 'todos', 'atletas', 'correr√£o', 'tempo', 'correr√£o', 'primeira', 'vez', 'prova', 'corredores', 'profissionais', 'correr√£o', 'pr√≥xima', 'competi√ß√£o', 'correr√£o', 'maratona', 'pr√≥ximo', 'm√™s', 'competidores', 'correr√£o', 'diferentes', 'categorias', 'todos', 'atletas', 'correr√£o', 'tempo', 'correr√£o', 'primeira', 'vez', 'prova', 'corredores', 'profissionais', 'correr√£o', 'pr√≥xima', 'competi√ß√£o', 'garoto', 'correu', 'escola', 'atrasar', 'correu', 'maratona', 'inteira', 'parar', 'assim', 'ouviu', 'not√≠cia', 'correu', 'casa', 'cachorro', 'correu', 'dire√ß√£o', 'port√£o', 'correu', 'pegar', '√∫ltimo', 'trem', 'noite', 'garoto', 'correu', 'escola', 'atrasar', 'correu', 'maratona', 'inteira', 'parar', 'assim', 'ouviu', 'not√≠cia', 'correu', 'casa', 'cachorro', 'correu', 'dire√ß√£o', 'port√£o', 'correu', 'pegar', '√∫ltimo', 'trem', 'noite', 'garoto', 'correu', 'escola', 'atrasar', 'correu', 'maratona', 'inteira', 'parar', 'assim', 'ouviu', 'not√≠cia', 'correu', 'casa', 'cachorro', 'correu', 'dire√ß√£o', 'port√£o', 'correu', 'pegar', '√∫ltimo', 'trem', 'noite', 'garoto', 'correu', 'escola', 'atrasar', 'correu', 'maratona', 'inteira', 'parar', 'assim', 'ouviu', 'not√≠cia', 'correu', 'casa', 'cachorro', 'correu', 'dire√ß√£o', 'port√£o', 'correu', 'pegar', '√∫ltimo', 'trem', 'noite', 'garoto', 'correu', 'escola', 'atrasar', 'correu', 'maratona', 'inteira', 'parar', 'assim', 'ouviu', 'not√≠cia', 'correu', 'casa', 'cachorro', 'correu', 'dire√ß√£o', 'port√£o', 'correu', 'pegar', '√∫ltimo', 'trem', 'noite', 'garoto', 'correu', 'escola', 'atrasar', 'correu', 'maratona', 'inteira', 'parar', 'assim', 'ouviu', 'not√≠cia', 'correu', 'casa', 'cachorro', 'correu', 'dire√ß√£o', 'port√£o', 'correu', 'pegar', '√∫ltimo', 'trem', 'noite', 'garoto', 'correu', 'escola', 'atrasar', 'correu', 'maratona', 'inteira', 'parar', 'assim', 'ouviu', 'not√≠cia', 'correu', 'casa', 'cachorro', 'correu', 'dire√ß√£o', 'port√£o', 'correu', 'pegar', '√∫ltimo', 'trem', 'noite', 'corrida', 'carros', 'amanh√£', 'manh√£', 'treinou', 'corrida', 'hoje', 'corrida', 'come√ßou', 'manh√£', 'participaram', 'corrida', 'beneficente', 'domingo', 'todos', 'ansiosos', 'grande', 'corrida', 'corrida', 'carros', 'amanh√£', 'manh√£', 'treinou', 'corrida', 'hoje', 'corrida', 'come√ßou', 'manh√£', 'participaram', 'corrida', 'beneficente', 'domingo', 'todos', 'ansiosos', 'grande', 'corrida', 'corrida', 'carros', 'amanh√£', 'manh√£', 'treinou', 'corrida', 'hoje', 'corrida', 'come√ßou', 'manh√£', 'participaram', 'corrida', 'beneficente', 'domingo', 'todos', 'ansiosos', 'grande', 'corrida', 'corrida', 'carros', 'amanh√£', 'manh√£', 'treinou', 'corrida', 'hoje', 'corrida', 'come√ßou', 'manh√£', 'participaram', 'corrida', 'beneficente', 'domingo', 'todos', 'ansiosos', 'grande', 'corrida', 'corrida', 'carros', 'amanh√£', 'manh√£', 'treinou', 'corrida', 'hoje', 'corrida', 'come√ßou', 'manh√£', 'participaram', 'corrida', 'beneficente', 'domingo', 'todos', 'ansiosos', 'grande', 'corrida', 'corrida', 'carros', 'amanh√£', 'manh√£', 'treinou', 'corrida', 'hoje', 'corrida', 'come√ßou', 'manh√£', 'participaram', 'corrida', 'beneficente', 'domingo', 'todos', 'ansiosos', 'grande', 'corrida']\n",
            "Tokens lematizados:  [880]['ontem', 'correr', 'cinco', 'quil√¥metro', 'parque', 'cachorro', 'come√ßar', 'latir', 'rapidamente', 'correr', 'casa', 'correr', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvir', 'not√≠cia', 'correr', 'contar', 'amigo', 'Escola', 'correr', 'parque', 'encontrar', 'amigo', 'ontem', 'correr', 'cinco', 'quil√¥metro', 'parque', 'cachorro', 'come√ßar', 'latir', 'rapidamente', 'correr', 'casa', 'correr', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvir', 'not√≠cia', 'correr', 'contar', 'amigo', 'Escola', 'correr', 'parque', 'encontrar', 'amigo', 'ontem', 'correr', 'cinco', 'quil√¥metro', 'parque', 'cachorro', 'come√ßar', 'latir', 'rapidamente', 'correr', 'casa', 'correr', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvir', 'not√≠cia', 'correr', 'contar', 'amigo', 'Escola', 'correr', 'parque', 'encontrar', 'amigo', 'ontem', 'correr', 'cinco', 'quil√¥metro', 'parque', 'cachorro', 'come√ßar', 'latir', 'rapidamente', 'correr', 'casa', 'correr', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvir', 'not√≠cia', 'correr', 'contar', 'amigo', 'Escola', 'correr', 'parque', 'encontrar', 'amigo', 'ontem', 'correr', 'cinco', 'quil√¥metro', 'parque', 'cachorro', 'come√ßar', 'latir', 'rapidamente', 'correr', 'casa', 'correr', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvir', 'not√≠cia', 'correr', 'contar', 'amigo', 'Escola', 'correr', 'parque', 'encontrar', 'amigo', 'ontem', 'correr', 'cinco', 'quil√¥metro', 'parque', 'cachorro', 'come√ßar', 'latir', 'rapidamente', 'correr', 'casa', 'correr', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvir', 'not√≠cia', 'correr', 'contar', 'amigo', 'Escola', 'correr', 'parque', 'encontrar', 'amigo', 'ontem', 'correr', 'cinco', 'quil√¥metro', 'parque', 'cachorro', 'come√ßar', 'latir', 'rapidamente', 'correr', 'casa', 'correr', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvir', 'not√≠cia', 'correr', 'contar', 'amigo', 'Escola', 'correr', 'parque', 'encontrar', 'amigo', 'ontem', 'correr', 'cinco', 'quil√¥metro', 'parque', 'cachorro', 'come√ßar', 'latir', 'rapidamente', 'correr', 'casa', 'correr', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvir', 'not√≠cia', 'correr', 'contar', 'amigo', 'Escola', 'correr', 'parque', 'encontrar', 'amigo', 'ontem', 'correr', 'cinco', 'quil√¥metro', 'parque', 'cachorro', 'come√ßar', 'latir', 'rapidamente', 'correr', 'casa', 'correr', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvir', 'not√≠cia', 'correr', 'contar', 'amigo', 'Escola', 'correr', 'parque', 'encontrar', 'amigo', 'ontem', 'correr', 'cinco', 'quil√¥metro', 'parque', 'cachorro', 'come√ßar', 'latir', 'rapidamente', 'correr', 'casa', 'correr', 'r√°pido', 'pude', 'perder', '√¥nibus', 'assim', 'ouvir', 'not√≠cia', 'correr', 'contar', 'amigo', 'Escola', 'correr', 'parque', 'encontrar', 'amigo', 'correr', 'pegar', '√¥nibus', 'atleta', 'correr', 'volta', 'pista', 'ver', 'grupo', 'pessoa', 'correr', 'parque', 'crian√ßa', 'correr', 'brincar', 'Jardim', 'cachorro', 'correr', 'atr√°s', 'bola', 'correr', 'pegar', '√¥nibus', 'atleta', 'correr', 'volta', 'pista', 'ver', 'grupo', 'pessoa', 'correr', 'parque', 'crian√ßa', 'correr', 'brincar', 'Jardim', 'cachorro', 'correr', 'atr√°s', 'bola', 'correr', 'pegar', '√¥nibus', 'atleta', 'correr', 'volta', 'pista', 'ver', 'grupo', 'pessoa', 'correr', 'parque', 'crian√ßa', 'correr', 'brincar', 'Jardim', 'cachorro', 'correr', 'atr√°s', 'bola', 'correr', 'pegar', '√¥nibus', 'atleta', 'correr', 'volta', 'pista', 'ver', 'grupo', 'pessoa', 'correr', 'parque', 'crian√ßa', 'correr', 'brincar', 'Jardim', 'cachorro', 'correr', 'atr√°s', 'bola', 'correr', 'pegar', '√¥nibus', 'atleta', 'correr', 'volta', 'pista', 'ver', 'grupo', 'pessoa', 'correr', 'parque', 'crian√ßa', 'correr', 'brincar', 'Jardim', 'cachorro', 'correr', 'atr√°s', 'bola', 'correr', 'pegar', '√¥nibus', 'atleta', 'correr', 'volta', 'pista', 'ver', 'grupo', 'pessoa', 'correr', 'parque', 'crian√ßa', 'correr', 'brincar', 'Jardim', 'cachorro', 'correr', 'atr√°s', 'bola', 'correr', 'pegar', '√¥nibus', 'atleta', 'correr', 'volta', 'pista', 'ver', 'grupo', 'pessoa', 'correr', 'parque', 'crian√ßa', 'correr', 'brincar', 'Jardim', 'cachorro', 'correr', 'atr√°s', 'bola', 'correr', 'pegar', '√¥nibus', 'atleta', 'correr', 'volta', 'pista', 'ver', 'grupo', 'pessoa', 'correr', 'parque', 'crian√ßa', 'correr', 'brincar', 'Jardim', 'cachorro', 'correr', 'atr√°s', 'bola', 'correr', 'pegar', '√¥nibus', 'atleta', 'correr', 'volta', 'pista', 'ver', 'grupo', 'pessoa', 'correr', 'parque', 'crian√ßa', 'correr', 'brincar', 'Jardim', 'cachorro', 'correr', 'atr√°s', 'bola', 'correr', 'maratonar', 'pr√≥ximo', 'm√™s', 'competidor', 'correr', 'diferente', 'categoria', 'todo', 'atleta', 'correr', 'tempo', 'correr', 'primeira', 'vez', 'prova', 'corredor', 'profissional', 'correr', 'pr√≥ximo', 'competi√ß√£o', 'correr', 'maratonar', 'pr√≥ximo', 'm√™s', 'competidor', 'correr', 'diferente', 'categoria', 'todo', 'atleta', 'correr', 'tempo', 'correr', 'primeira', 'vez', 'prova', 'corredor', 'profissional', 'correr', 'pr√≥ximo', 'competi√ß√£o', 'correr', 'maratonar', 'pr√≥ximo', 'm√™s', 'competidor', 'correr', 'diferente', 'categoria', 'todo', 'atleta', 'correr', 'tempo', 'correr', 'primeira', 'vez', 'prova', 'corredor', 'profissional', 'correr', 'pr√≥ximo', 'competi√ß√£o', 'correr', 'maratonar', 'pr√≥ximo', 'm√™s', 'competidor', 'correr', 'diferente', 'categoria', 'todo', 'atleta', 'correr', 'tempo', 'correr', 'primeira', 'vez', 'prova', 'corredor', 'profissional', 'correr', 'pr√≥ximo', 'competi√ß√£o', 'correr', 'maratonar', 'pr√≥ximo', 'm√™s', 'competidor', 'correr', 'diferente', 'categoria', 'todo', 'atleta', 'correr', 'tempo', 'correr', 'primeira', 'vez', 'prova', 'corredor', 'profissional', 'correr', 'pr√≥ximo', 'competi√ß√£o', 'correr', 'maratonar', 'pr√≥ximo', 'm√™s', 'competidor', 'correr', 'diferente', 'categoria', 'todo', 'atleta', 'correr', 'tempo', 'correr', 'primeira', 'vez', 'prova', 'corredor', 'profissional', 'correr', 'pr√≥ximo', 'competi√ß√£o', 'correr', 'maratonar', 'pr√≥ximo', 'm√™s', 'competidor', 'correr', 'diferente', 'categoria', 'todo', 'atleta', 'correr', 'tempo', 'correr', 'primeira', 'vez', 'prova', 'corredor', 'profissional', 'correr', 'pr√≥ximo', 'competi√ß√£o', 'correr', 'maratonar', 'pr√≥ximo', 'm√™s', 'competidor', 'correr', 'diferente', 'categoria', 'todo', 'atleta', 'correr', 'tempo', 'correr', 'primeira', 'vez', 'prova', 'corredor', 'profissional', 'correr', 'pr√≥ximo', 'competi√ß√£o', 'garoto', 'correr', 'escola', 'atrasar', 'correr', 'maratona', 'inteirar', 'parar', 'assim', 'ouvir', 'not√≠cia', 'correr', 'casa', 'cachorro', 'correr', 'dire√ß√£o', 'port√£o', 'correr', 'pegar', '√∫ltimo', 'tr', 'noite', 'garoto', 'correr', 'escola', 'atrasar', 'correr', 'maratona', 'inteirar', 'parar', 'assim', 'ouvir', 'not√≠cia', 'correr', 'casa', 'cachorro', 'correr', 'dire√ß√£o', 'port√£o', 'correr', 'pegar', '√∫ltimo', 'tr', 'noite', 'garoto', 'correr', 'escola', 'atrasar', 'correr', 'maratona', 'inteirar', 'parar', 'assim', 'ouvir', 'not√≠cia', 'correr', 'casa', 'cachorro', 'correr', 'dire√ß√£o', 'port√£o', 'correr', 'pegar', '√∫ltimo', 'tr', 'noite', 'garoto', 'correr', 'escola', 'atrasar', 'correr', 'maratona', 'inteirar', 'parar', 'assim', 'ouvir', 'not√≠cia', 'correr', 'casa', 'cachorro', 'correr', 'dire√ß√£o', 'port√£o', 'correr', 'pegar', '√∫ltimo', 'tr', 'noite', 'garoto', 'correr', 'escola', 'atrasar', 'correr', 'maratona', 'inteirar', 'parar', 'assim', 'ouvir', 'not√≠cia', 'correr', 'casa', 'cachorro', 'correr', 'dire√ß√£o', 'port√£o', 'correr', 'pegar', '√∫ltimo', 'tr', 'noite', 'garoto', 'correr', 'escola', 'atrasar', 'correr', 'maratona', 'inteirar', 'parar', 'assim', 'ouvir', 'not√≠cia', 'correr', 'casa', 'cachorro', 'correr', 'dire√ß√£o', 'port√£o', 'correr', 'pegar', '√∫ltimo', 'tr', 'noite', 'garoto', 'correr', 'escola', 'atrasar', 'correr', 'maratona', 'inteirar', 'parar', 'assim', 'ouvir', 'not√≠cia', 'correr', 'casa', 'cachorro', 'correr', 'dire√ß√£o', 'port√£o', 'correr', 'pegar', '√∫ltimo', 'tr', 'noite', 'correr', 'carro', 'amanh√£', 'manh√£', 'treinar', 'correr', 'hoje', 'correr', 'come√ßar', 'manh√£', 'participar', 'correr', 'beneficente', 'domingo', 'todo', 'ansioso', 'grande', 'correr', 'correr', 'carro', 'amanh√£', 'manh√£', 'treinar', 'correr', 'hoje', 'correr', 'come√ßar', 'manh√£', 'participar', 'correr', 'beneficente', 'domingo', 'todo', 'ansioso', 'grande', 'correr', 'correr', 'carro', 'amanh√£', 'manh√£', 'treinar', 'correr', 'hoje', 'correr', 'come√ßar', 'manh√£', 'participar', 'correr', 'beneficente', 'domingo', 'todo', 'ansioso', 'grande', 'correr', 'correr', 'carro', 'amanh√£', 'manh√£', 'treinar', 'correr', 'hoje', 'correr', 'come√ßar', 'manh√£', 'participar', 'correr', 'beneficente', 'domingo', 'todo', 'ansioso', 'grande', 'correr', 'correr', 'carro', 'amanh√£', 'manh√£', 'treinar', 'correr', 'hoje', 'correr', 'come√ßar', 'manh√£', 'participar', 'correr', 'beneficente', 'domingo', 'todo', 'ansioso', 'grande', 'correr', 'correr', 'carro', 'amanh√£', 'manh√£', 'treinar', 'correr', 'hoje', 'correr', 'come√ßar', 'manh√£', 'participar', 'correr', 'beneficente', 'domingo', 'todo', 'ansioso', 'grande', 'correr']\n",
            "Lemas √∫nicos:  [68]['r√°pido', 'cachorro', 'carro', '√¥nibus', 'prova', 'pegar', 'inteirar', 'parar', 'vez', 'amanh√£', 'grande', 'noite', 'pista', 'domingo', 'todo', 'primeira', 'atr√°s', 'atrasar', 'amigo', 'pessoa', 'Escola', 'brincar', 'Jardim', 'contar', 'diferente', 'crian√ßa', 'assim', 'ontem', 'quil√¥metro', 'rapidamente', 'casa', 'maratonar', 'port√£o', 'ouvir', 'manh√£', 'come√ßar', 'pude', 'parque', 'pr√≥ximo', 'profissional', 'maratona', 'correr', 'tr', 'treinar', 'ansioso', 'ver', 'encontrar', 'tempo', 'participar', 'perder', 'competi√ß√£o', 'categoria', 'latir', 'corredor', 'competidor', 'hoje', 'atleta', 'grupo', 'beneficente', 'garoto', 'bola', '√∫ltimo', 'dire√ß√£o', 'volta', 'escola', 'cinco', 'm√™s', 'not√≠cia']\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Frequ√™ncia de palavras antes da lematiza√ß√£o:\n",
            "ontem: 10\n",
            "corri: 50\n",
            "cinco: 10\n",
            "quil√¥metros: 10\n",
            "parque: 29\n",
            "cachorro: 26\n",
            "come√ßou: 16\n",
            "latir: 10\n",
            "rapidamente: 10\n",
            "casa: 17\n",
            "r√°pido: 10\n",
            "pude: 10\n",
            "perder: 10\n",
            "√¥nibus: 19\n",
            "assim: 17\n",
            "ouvi: 10\n",
            "not√≠cia: 17\n",
            "contar: 10\n",
            "amigos: 20\n",
            "escola: 17\n",
            "encontrar: 10\n",
            "correndo: 45\n",
            "pegar: 16\n",
            "atletas: 17\n",
            "volta: 9\n",
            "pista: 9\n",
            "vi: 9\n",
            "grupo: 9\n",
            "pessoas: 9\n",
            "crian√ßas: 9\n",
            "brincando: 9\n",
            "jardim: 9\n",
            "atr√°s: 9\n",
            "bola: 9\n",
            "correr√£o: 40\n",
            "maratona: 15\n",
            "pr√≥ximo: 8\n",
            "m√™s: 8\n",
            "competidores: 8\n",
            "diferentes: 8\n",
            "categorias: 8\n",
            "todos: 14\n",
            "tempo: 8\n",
            "primeira: 8\n",
            "vez: 8\n",
            "prova: 8\n",
            "corredores: 8\n",
            "profissionais: 8\n",
            "pr√≥xima: 8\n",
            "competi√ß√£o: 8\n",
            "garoto: 7\n",
            "correu: 35\n",
            "atrasar: 7\n",
            "inteira: 7\n",
            "parar: 7\n",
            "ouviu: 7\n",
            "dire√ß√£o: 7\n",
            "port√£o: 7\n",
            "√∫ltimo: 7\n",
            "trem: 7\n",
            "noite: 7\n",
            "corrida: 30\n",
            "carros: 6\n",
            "amanh√£: 6\n",
            "manh√£: 12\n",
            "treinou: 6\n",
            "hoje: 6\n",
            "participaram: 6\n",
            "beneficente: 6\n",
            "domingo: 6\n",
            "ansiosos: 6\n",
            "grande: 6\n",
            "\n",
            "\n",
            "Frequ√™ncia de palavras ap√≥s a lematiza√ß√£o:\n",
            "ontem: 10\n",
            "correr: 200\n",
            "cinco: 10\n",
            "quil√¥metro: 10\n",
            "parque: 29\n",
            "cachorro: 26\n",
            "come√ßar: 16\n",
            "latir: 10\n",
            "rapidamente: 10\n",
            "casa: 17\n",
            "r√°pido: 10\n",
            "pude: 10\n",
            "perder: 10\n",
            "√¥nibus: 19\n",
            "assim: 17\n",
            "ouvir: 17\n",
            "not√≠cia: 17\n",
            "contar: 10\n",
            "amigo: 20\n",
            "Escola: 10\n",
            "encontrar: 10\n",
            "pegar: 16\n",
            "atleta: 17\n",
            "volta: 9\n",
            "pista: 9\n",
            "ver: 9\n",
            "grupo: 9\n",
            "pessoa: 9\n",
            "crian√ßa: 9\n",
            "brincar: 9\n",
            "Jardim: 9\n",
            "atr√°s: 9\n",
            "bola: 9\n",
            "maratonar: 8\n",
            "pr√≥ximo: 16\n",
            "m√™s: 8\n",
            "competidor: 8\n",
            "diferente: 8\n",
            "categoria: 8\n",
            "todo: 14\n",
            "tempo: 8\n",
            "primeira: 8\n",
            "vez: 8\n",
            "prova: 8\n",
            "corredor: 8\n",
            "profissional: 8\n",
            "competi√ß√£o: 8\n",
            "garoto: 7\n",
            "escola: 7\n",
            "atrasar: 7\n",
            "maratona: 7\n",
            "inteirar: 7\n",
            "parar: 7\n",
            "dire√ß√£o: 7\n",
            "port√£o: 7\n",
            "√∫ltimo: 7\n",
            "tr: 7\n",
            "noite: 7\n",
            "carro: 6\n",
            "amanh√£: 6\n",
            "manh√£: 12\n",
            "treinar: 6\n",
            "hoje: 6\n",
            "participar: 6\n",
            "beneficente: 6\n",
            "domingo: 6\n",
            "ansioso: 6\n",
            "grande: 6\n"
          ]
        }
      ],
      "source": [
        "# Etapa 1: Verifica√ß√£o e Instala√ß√£o das Bibliotecas Necess√°rias\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_and_import(package):\n",
        "    try:\n",
        "        __import__(package)\n",
        "    except ImportError:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Instalar as bibliotecas necess√°rias\n",
        "install_and_import('spacy')\n",
        "\n",
        "\n",
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Baixar o modelo de portugu√™s do spaCy, caso n√£o esteja instalado\n",
        "subprocess.run([sys.executable, \"-m\", \"spacy\", \"download\", \"pt_core_news_sm\"])\n",
        "\n",
        "# Baixar os recursos necess√°rios\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Carregar o modelo de linguagem do spaCy para lematiza√ß√£o em portugu√™s\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "# Conjunto de frases de exemplo em portugu√™s\n",
        "frases = [\n",
        "    \"\"\"Ontem, eu corri cinco quil√¥metros no parque.\"\"\"\n",
        "    \"\"\"Quando o cachorro come√ßou a latir, eu rapidamente corri para casa.\"\"\"\n",
        "    \"\"\"Corri o mais r√°pido que pude para n√£o perder o √¥nibus.\"\"\"\n",
        "    \"\"\"Assim que ouvi a not√≠cia, corri para contar aos meus amigos.\"\"\"\n",
        "    \"\"\"Depois da escola, corri para o parque encontrar meus amigos.\"\"\"\n",
        "    \"\"\"Ontem, eu corri cinco quil√¥metros no parque.\"\"\"\n",
        "    \"\"\"Quando o cachorro come√ßou a latir, eu rapidamente corri para casa.\"\"\"\n",
        "    \"\"\"Corri o mais r√°pido que pude para n√£o perder o √¥nibus.\"\"\"\n",
        "    \"\"\"Assim que ouvi a not√≠cia, corri para contar aos meus amigos.\"\"\"\n",
        "    \"\"\"Depois da escola, corri para o parque encontrar meus amigos.\"\"\"\n",
        "    \"\"\"Ontem, eu corri cinco quil√¥metros no parque.\"\"\"\n",
        "    \"\"\"Quando o cachorro come√ßou a latir, eu rapidamente corri para casa.\"\"\"\n",
        "    \"\"\"Corri o mais r√°pido que pude para n√£o perder o √¥nibus.\"\"\"\n",
        "    \"\"\"Assim que ouvi a not√≠cia, corri para contar aos meus amigos.\"\"\"\n",
        "    \"\"\"Depois da escola, corri para o parque encontrar meus amigos.\"\"\"\n",
        "    \"\"\"Ontem, eu corri cinco quil√¥metros no parque.\"\"\"\n",
        "    \"\"\"Quando o cachorro come√ßou a latir, eu rapidamente corri para casa.\"\"\"\n",
        "    \"\"\"Corri o mais r√°pido que pude para n√£o perder o √¥nibus.\"\"\"\n",
        "    \"\"\"Assim que ouvi a not√≠cia, corri para contar aos meus amigos.\"\"\"\n",
        "    \"\"\"Depois da escola, corri para o parque encontrar meus amigos.\"\"\"\n",
        "    \"\"\"Ontem, eu corri cinco quil√¥metros no parque.\"\"\"\n",
        "    \"\"\"Quando o cachorro come√ßou a latir, eu rapidamente corri para casa.\"\"\"\n",
        "    \"\"\"Corri o mais r√°pido que pude para n√£o perder o √¥nibus.\"\"\"\n",
        "    \"\"\"Assim que ouvi a not√≠cia, corri para contar aos meus amigos.\"\"\"\n",
        "    \"\"\"Depois da escola, corri para o parque encontrar meus amigos.\"\"\"\n",
        "    \"\"\"Ontem, eu corri cinco quil√¥metros no parque.\"\"\"\n",
        "    \"\"\"Quando o cachorro come√ßou a latir, eu rapidamente corri para casa.\"\"\"\n",
        "    \"\"\"Corri o mais r√°pido que pude para n√£o perder o √¥nibus.\"\"\"\n",
        "    \"\"\"Assim que ouvi a not√≠cia, corri para contar aos meus amigos.\"\"\"\n",
        "    \"\"\"Depois da escola, corri para o parque encontrar meus amigos.\"\"\"\n",
        "    \"\"\"Ontem, eu corri cinco quil√¥metros no parque.\"\"\"\n",
        "    \"\"\"Quando o cachorro come√ßou a latir, eu rapidamente corri para casa.\"\"\"\n",
        "    \"\"\"Corri o mais r√°pido que pude para n√£o perder o √¥nibus.\"\"\"\n",
        "    \"\"\"Assim que ouvi a not√≠cia, corri para contar aos meus amigos.\"\"\"\n",
        "    \"\"\"Depois da escola, corri para o parque encontrar meus amigos.\"\"\"\n",
        "    \"\"\"Ontem, eu corri cinco quil√¥metros no parque.\"\"\"\n",
        "    \"\"\"Quando o cachorro come√ßou a latir, eu rapidamente corri para casa.\"\"\"\n",
        "    \"\"\"Corri o mais r√°pido que pude para n√£o perder o √¥nibus.\"\"\"\n",
        "    \"\"\"Assim que ouvi a not√≠cia, corri para contar aos meus amigos.\"\"\"\n",
        "    \"\"\"Depois da escola, corri para o parque encontrar meus amigos.\"\"\"\n",
        "    \"\"\"Ontem, eu corri cinco quil√¥metros no parque.\"\"\"\n",
        "    \"\"\"Quando o cachorro come√ßou a latir, eu rapidamente corri para casa.\"\"\"\n",
        "    \"\"\"Corri o mais r√°pido que pude para n√£o perder o √¥nibus.\"\"\"\n",
        "    \"\"\"Assim que ouvi a not√≠cia, corri para contar aos meus amigos.\"\"\"\n",
        "    \"\"\"Depois da escola, corri para o parque encontrar meus amigos.\"\"\"\n",
        "    \"\"\"Ontem, eu corri cinco quil√¥metros no parque.\"\"\"\n",
        "    \"\"\"Quando o cachorro come√ßou a latir, eu rapidamente corri para casa.\"\"\"\n",
        "    \"\"\"Corri o mais r√°pido que pude para n√£o perder o √¥nibus.\"\"\"\n",
        "    \"\"\"Assim que ouvi a not√≠cia, corri para contar aos meus amigos.\"\"\"\n",
        "    \"\"\"Depois da escola, corri para o parque encontrar meus amigos.\"\"\"\n",
        "    \"\"\"Ela estava correndo para pegar o √¥nibus.\"\"\"\n",
        "    \"\"\"Os atletas est√£o correndo em volta da pista.\"\"\"\n",
        "    \"\"\"Vi um grupo de pessoas correndo no parque.\"\"\"\n",
        "    \"\"\"As crian√ßas estavam correndo e brincando no jardim.\"\"\"\n",
        "    \"\"\"O cachorro estava correndo atr√°s da bola.\"\"\"\n",
        "    \"\"\"Ela estava correndo para pegar o √¥nibus.\"\"\"\n",
        "    \"\"\"Os atletas est√£o correndo em volta da pista.\"\"\"\n",
        "    \"\"\"Vi um grupo de pessoas correndo no parque.\"\"\"\n",
        "    \"\"\"As crian√ßas estavam correndo e brincando no jardim.\"\"\"\n",
        "    \"\"\"O cachorro estava correndo atr√°s da bola.\"\"\"\n",
        "    \"\"\"Ela estava correndo para pegar o √¥nibus.\"\"\"\n",
        "    \"\"\"Os atletas est√£o correndo em volta da pista.\"\"\"\n",
        "    \"\"\"Vi um grupo de pessoas correndo no parque.\"\"\"\n",
        "    \"\"\"As crian√ßas estavam correndo e brincando no jardim.\"\"\"\n",
        "    \"\"\"O cachorro estava correndo atr√°s da bola.\"\"\"\n",
        "    \"\"\"Ela estava correndo para pegar o √¥nibus.\"\"\"\n",
        "    \"\"\"Os atletas est√£o correndo em volta da pista.\"\"\"\n",
        "    \"\"\"Vi um grupo de pessoas correndo no parque.\"\"\"\n",
        "    \"\"\"As crian√ßas estavam correndo e brincando no jardim.\"\"\"\n",
        "    \"\"\"O cachorro estava correndo atr√°s da bola.\"\"\"\n",
        "    \"\"\"Ela estava correndo para pegar o √¥nibus.\"\"\"\n",
        "    \"\"\"Os atletas est√£o correndo em volta da pista.\"\"\"\n",
        "    \"\"\"Vi um grupo de pessoas correndo no parque.\"\"\"\n",
        "    \"\"\"As crian√ßas estavam correndo e brincando no jardim.\"\"\"\n",
        "    \"\"\"O cachorro estava correndo atr√°s da bola.\"\"\"\n",
        "    \"\"\"Ela estava correndo para pegar o √¥nibus.\"\"\"\n",
        "    \"\"\"Os atletas est√£o correndo em volta da pista.\"\"\"\n",
        "    \"\"\"Vi um grupo de pessoas correndo no parque.\"\"\"\n",
        "    \"\"\"As crian√ßas estavam correndo e brincando no jardim.\"\"\"\n",
        "    \"\"\"O cachorro estava correndo atr√°s da bola.\"\"\"\n",
        "    \"\"\"Ela estava correndo para pegar o √¥nibus.\"\"\"\n",
        "    \"\"\"Os atletas est√£o correndo em volta da pista.\"\"\"\n",
        "    \"\"\"Vi um grupo de pessoas correndo no parque.\"\"\"\n",
        "    \"\"\"As crian√ßas estavam correndo e brincando no jardim.\"\"\"\n",
        "    \"\"\"O cachorro estava correndo atr√°s da bola.\"\"\"\n",
        "    \"\"\"Ela estava correndo para pegar o √¥nibus.\"\"\"\n",
        "    \"\"\"Os atletas est√£o correndo em volta da pista.\"\"\"\n",
        "    \"\"\"Vi um grupo de pessoas correndo no parque.\"\"\"\n",
        "    \"\"\"As crian√ßas estavam correndo e brincando no jardim.\"\"\"\n",
        "    \"\"\"O cachorro estava correndo atr√°s da bola.\"\"\"\n",
        "    \"\"\"Ela estava correndo para pegar o √¥nibus.\"\"\"\n",
        "    \"\"\"Os atletas est√£o correndo em volta da pista.\"\"\"\n",
        "    \"\"\"Vi um grupo de pessoas correndo no parque.\"\"\"\n",
        "    \"\"\"As crian√ßas estavam correndo e brincando no jardim.\"\"\"\n",
        "    \"\"\"O cachorro estava correndo atr√°s da bola.\"\"\"\n",
        "    \"\"\"Eles correr√£o na maratona no pr√≥ximo m√™s.\"\"\"\n",
        "    \"\"\"Os competidores correr√£o em diferentes categorias.\"\"\"\n",
        "    \"\"\"Todos os atletas correr√£o ao mesmo tempo.\"\"\"\n",
        "    \"\"\"Eles correr√£o pela primeira vez na prova.\"\"\"\n",
        "    \"\"\"Os corredores profissionais correr√£o na pr√≥xima competi√ß√£o.\"\"\"\n",
        "    \"\"\"Eles correr√£o na maratona no pr√≥ximo m√™s.\"\"\"\n",
        "    \"\"\"Os competidores correr√£o em diferentes categorias.\"\"\"\n",
        "    \"\"\"Todos os atletas correr√£o ao mesmo tempo.\"\"\"\n",
        "    \"\"\"Eles correr√£o pela primeira vez na prova.\"\"\"\n",
        "    \"\"\"Os corredores profissionais correr√£o na pr√≥xima competi√ß√£o.\"\"\"\n",
        "    \"\"\"Eles correr√£o na maratona no pr√≥ximo m√™s.\"\"\"\n",
        "    \"\"\"Os competidores correr√£o em diferentes categorias.\"\"\"\n",
        "    \"\"\"Todos os atletas correr√£o ao mesmo tempo.\"\"\"\n",
        "    \"\"\"Eles correr√£o pela primeira vez na prova.\"\"\"\n",
        "    \"\"\"Os corredores profissionais correr√£o na pr√≥xima competi√ß√£o.\"\"\"\n",
        "    \"\"\"Eles correr√£o na maratona no pr√≥ximo m√™s.\"\"\"\n",
        "    \"\"\"Os competidores correr√£o em diferentes categorias.\"\"\"\n",
        "    \"\"\"Todos os atletas correr√£o ao mesmo tempo.\"\"\"\n",
        "    \"\"\"Eles correr√£o pela primeira vez na prova.\"\"\"\n",
        "    \"\"\"Os corredores profissionais correr√£o na pr√≥xima competi√ß√£o.\"\"\"\n",
        "    \"\"\"Eles correr√£o na maratona no pr√≥ximo m√™s.\"\"\"\n",
        "    \"\"\"Os competidores correr√£o em diferentes categorias.\"\"\"\n",
        "    \"\"\"Todos os atletas correr√£o ao mesmo tempo.\"\"\"\n",
        "    \"\"\"Eles correr√£o pela primeira vez na prova.\"\"\"\n",
        "    \"\"\"Os corredores profissionais correr√£o na pr√≥xima competi√ß√£o.\"\"\"\n",
        "    \"\"\"Eles correr√£o na maratona no pr√≥ximo m√™s.\"\"\"\n",
        "    \"\"\"Os competidores correr√£o em diferentes categorias.\"\"\"\n",
        "    \"\"\"Todos os atletas correr√£o ao mesmo tempo.\"\"\"\n",
        "    \"\"\"Eles correr√£o pela primeira vez na prova.\"\"\"\n",
        "    \"\"\"Os corredores profissionais correr√£o na pr√≥xima competi√ß√£o.\"\"\"\n",
        "    \"\"\"Eles correr√£o na maratona no pr√≥ximo m√™s.\"\"\"\n",
        "    \"\"\"Os competidores correr√£o em diferentes categorias.\"\"\"\n",
        "    \"\"\"Todos os atletas correr√£o ao mesmo tempo.\"\"\"\n",
        "    \"\"\"Eles correr√£o pela primeira vez na prova.\"\"\"\n",
        "    \"\"\"Os corredores profissionais correr√£o na pr√≥xima competi√ß√£o.\"\"\"\n",
        "    \"\"\"Eles correr√£o na maratona no pr√≥ximo m√™s.\"\"\"\n",
        "    \"\"\"Os competidores correr√£o em diferentes categorias.\"\"\"\n",
        "    \"\"\"Todos os atletas correr√£o ao mesmo tempo.\"\"\"\n",
        "    \"\"\"Eles correr√£o pela primeira vez na prova.\"\"\"\n",
        "    \"\"\"Os corredores profissionais correr√£o na pr√≥xima competi√ß√£o.\"\"\"\n",
        "    \"\"\"O garoto correu para a escola para n√£o se atrasar.\"\"\"\n",
        "    \"\"\"Ele correu a maratona inteira sem parar.\"\"\"\n",
        "    \"\"\"Assim que ouviu a not√≠cia, correu para casa.\"\"\"\n",
        "    \"\"\"O cachorro correu em dire√ß√£o ao port√£o.\"\"\"\n",
        "    \"\"\"Ela correu para pegar o √∫ltimo trem da noite.\"\"\"\n",
        "    \"\"\"O garoto correu para a escola para n√£o se atrasar.\"\"\"\n",
        "    \"\"\"Ele correu a maratona inteira sem parar.\"\"\"\n",
        "    \"\"\"Assim que ouviu a not√≠cia, correu para casa.\"\"\"\n",
        "    \"\"\"O cachorro correu em dire√ß√£o ao port√£o.\"\"\"\n",
        "    \"\"\"Ela correu para pegar o √∫ltimo trem da noite.\"\"\"\n",
        "    \"\"\"O garoto correu para a escola para n√£o se atrasar.\"\"\"\n",
        "    \"\"\"Ele correu a maratona inteira sem parar.\"\"\"\n",
        "    \"\"\"Assim que ouviu a not√≠cia, correu para casa.\"\"\"\n",
        "    \"\"\"O cachorro correu em dire√ß√£o ao port√£o.\"\"\"\n",
        "    \"\"\"Ela correu para pegar o √∫ltimo trem da noite.\"\"\"\n",
        "    \"\"\"O garoto correu para a escola para n√£o se atrasar.\"\"\"\n",
        "    \"\"\"Ele correu a maratona inteira sem parar.\"\"\"\n",
        "    \"\"\"Assim que ouviu a not√≠cia, correu para casa.\"\"\"\n",
        "    \"\"\"O cachorro correu em dire√ß√£o ao port√£o.\"\"\"\n",
        "    \"\"\"Ela correu para pegar o √∫ltimo trem da noite.\"\"\"\n",
        "    \"\"\"O garoto correu para a escola para n√£o se atrasar.\"\"\"\n",
        "    \"\"\"Ele correu a maratona inteira sem parar.\"\"\"\n",
        "    \"\"\"Assim que ouviu a not√≠cia, correu para casa.\"\"\"\n",
        "    \"\"\"O cachorro correu em dire√ß√£o ao port√£o.\"\"\"\n",
        "    \"\"\"Ela correu para pegar o √∫ltimo trem da noite.\"\"\"\n",
        "    \"\"\"O garoto correu para a escola para n√£o se atrasar.\"\"\"\n",
        "    \"\"\"Ele correu a maratona inteira sem parar.\"\"\"\n",
        "    \"\"\"Assim que ouviu a not√≠cia, correu para casa.\"\"\"\n",
        "    \"\"\"O cachorro correu em dire√ß√£o ao port√£o.\"\"\"\n",
        "    \"\"\"Ela correu para pegar o √∫ltimo trem da noite.\"\"\"\n",
        "    \"\"\"O garoto correu para a escola para n√£o se atrasar.\"\"\"\n",
        "    \"\"\"Ele correu a maratona inteira sem parar.\"\"\"\n",
        "    \"\"\"Assim que ouviu a not√≠cia, correu para casa.\"\"\"\n",
        "    \"\"\"O cachorro correu em dire√ß√£o ao port√£o.\"\"\"\n",
        "    \"\"\"Ela correu para pegar o √∫ltimo trem da noite.\"\"\"\n",
        "    \"\"\"A corrida de carros ser√° amanh√£ de manh√£.\"\"\"\n",
        "    \"\"\"Ela treinou muito para a corrida de hoje.\"\"\"\n",
        "    \"\"\"A corrida come√ßou √†s 7 da manh√£.\"\"\"\n",
        "    \"\"\"Eles participaram da corrida beneficente no domingo.\"\"\"\n",
        "    \"\"\"Todos estavam ansiosos pela grande corrida.\"\"\"\n",
        "    \"\"\"A corrida de carros ser√° amanh√£ de manh√£.\"\"\"\n",
        "    \"\"\"Ela treinou muito para a corrida de hoje.\"\"\"\n",
        "    \"\"\"A corrida come√ßou √†s 7 da manh√£.\"\"\"\n",
        "    \"\"\"Eles participaram da corrida beneficente no domingo.\"\"\"\n",
        "    \"\"\"Todos estavam ansiosos pela grande corrida.\"\"\"\n",
        "    \"\"\"A corrida de carros ser√° amanh√£ de manh√£.\"\"\"\n",
        "    \"\"\"Ela treinou muito para a corrida de hoje.\"\"\"\n",
        "    \"\"\"A corrida come√ßou √†s 7 da manh√£.\"\"\"\n",
        "    \"\"\"Eles participaram da corrida beneficente no domingo.\"\"\"\n",
        "    \"\"\"Todos estavam ansiosos pela grande corrida.\"\"\"\n",
        "    \"\"\"A corrida de carros ser√° amanh√£ de manh√£.\"\"\"\n",
        "    \"\"\"Ela treinou muito para a corrida de hoje.\"\"\"\n",
        "    \"\"\"A corrida come√ßou √†s 7 da manh√£.\"\"\"\n",
        "    \"\"\"Eles participaram da corrida beneficente no domingo.\"\"\"\n",
        "    \"\"\"Todos estavam ansiosos pela grande corrida.\"\"\"\n",
        "    \"\"\"A corrida de carros ser√° amanh√£ de manh√£.\"\"\"\n",
        "    \"\"\"Ela treinou muito para a corrida de hoje.\"\"\"\n",
        "    \"\"\"A corrida come√ßou √†s 7 da manh√£.\"\"\"\n",
        "    \"\"\"Eles participaram da corrida beneficente no domingo.\"\"\"\n",
        "    \"\"\"Todos estavam ansiosos pela grande corrida.\"\"\"\n",
        "    \"\"\"A corrida de carros ser√° amanh√£ de manh√£.\"\"\"\n",
        "    \"\"\"Ela treinou muito para a corrida de hoje.\"\"\"\n",
        "    \"\"\"A corrida come√ßou √†s 7 da manh√£.\"\"\"\n",
        "    \"\"\"Eles participaram da corrida beneficente no domingo.\"\"\"\n",
        "    \"\"\"Todos estavam ansiosos pela grande corrida.\"\"\"\n",
        "    ]\n",
        "\n",
        "# Fun√ß√£o para substituir pontua√ß√£o e n√∫meros por espa√ßos\n",
        "def substituir_pontuacao_numeros(frase):\n",
        "    tabela_traducao = str.maketrans(string.punctuation + '0123456789', ' ' * (len(string.punctuation) + 10))\n",
        "    return frase.translate(tabela_traducao)\n",
        "\n",
        "# Fun√ß√£o para processar cada frase\n",
        "def processar_frase(frase):\n",
        "    # Substituir pontua√ß√£o e n√∫meros por espa√ßos\n",
        "    frase_limpa = substituir_pontuacao_numeros(frase)\n",
        "\n",
        "    # Tokeniza√ß√£o\n",
        "    tokens = word_tokenize(frase_limpa)\n",
        "\n",
        "    # Remo√ß√£o de stopwords\n",
        "    stop_words = set(stopwords.words('portuguese'))\n",
        "    # len(stopwords) = 207, exemplos:\n",
        "    #{'pela', 'quando', 'h√°', 'estiver', 'mais', 'fomos', 'hajamos', 'esta',\n",
        "    # 'esteve', 'tiv√©ssemos', 'dos', 'houvesse', 'estas', 'eu', 'houveremos',\n",
        "    # 'pelos', 'ser√£o', 'tiveram', 'tua', 'tivessem', 't√©m', 'ter√≠amos', 'ter√£o',\n",
        "    # 'ele', 'houver', 'estava', 'depois', 'minhas', 'sejamos', 'tu', 'j√°', 'da',\n",
        "    #'teriam', 'tivera', 'este', 'por', 'era', 'isto', 'forem', 'na',\n",
        "    # ....\n",
        "    #}\n",
        "    tokens_sem_stopwords = [token for token in tokens if token.lower() not in stop_words]\n",
        "\n",
        "    # Lematiza√ß√£o com substitui√ß√£o manual\n",
        "    doc = nlp(\" \".join(tokens_sem_stopwords))\n",
        "    tokens_lematizados = []\n",
        "    for token in doc:\n",
        "        if token.text.lower() in [\"corri\", \"corrida\", \"correndo\", \"correu\", \"correr√£o\"]:\n",
        "            tokens_lematizados.append(\"correr\")\n",
        "        else:\n",
        "            tokens_lematizados.append(token.lemma_)\n",
        "\n",
        "    # Criar a lista de lemas √∫nicos\n",
        "    lemas_unicos = list(set(tokens_lematizados))\n",
        "\n",
        "    return tokens_sem_stopwords, tokens_lematizados, lemas_unicos\n",
        "\n",
        "# Processar cada frase no conjunto e calcular frequ√™ncias\n",
        "frequencia_original = Counter()\n",
        "frequencia_lematizada = Counter()\n",
        "\n",
        "for frase in frases:\n",
        "    tokens_sem_stopwords, tokens_lematizados, lemas_unicos = processar_frase(frase.lower())\n",
        "\n",
        "    frequencia_original.update(tokens_sem_stopwords)\n",
        "    frequencia_lematizada.update(tokens_lematizados)\n",
        "\n",
        "# Lista de palavras de interesse para o lema \"correr\"\n",
        "palavras_interesse_lema = [\"correr\"]\n",
        "\n",
        "# Dados de frequ√™ncia das palavras antes da lematiza√ß√£o\n",
        "palavras = [\"corri\", \"correndo\", \"correr√£o\", \"correu\", \"corrida\"]\n",
        "frequencias = []\n",
        "\n",
        "for i in palavras:\n",
        "    frequencias.append(frequencia_original[i])\n",
        "\n",
        "\n",
        "print(f\"Tokens ap√≥s remo√ß√£o de stopwords: [{len(tokens_sem_stopwords)}] {tokens_sem_stopwords}\")\n",
        "print(f\"Tokens lematizados:  [{len(tokens_lematizados)}]{tokens_lematizados}\")\n",
        "print(f\"Lemas √∫nicos:  [{len(lemas_unicos)}]{lemas_unicos}\\n\")\n",
        "\n",
        "\n",
        "# Dados de frequ√™ncia para o lema \"correr\" ap√≥s a lematiza√ß√£o\n",
        "lema = [\"correr\"]\n",
        "frequencia_lema = frequencia_lematizada[\"correr\"]\n",
        "\n",
        "# Gr√°fico de barras para as palavras antes da lematiza√ß√£o\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(palavras, frequencias, color='skyblue')\n",
        "plt.xlabel('Palavras')\n",
        "plt.ylabel('Frequ√™ncia')\n",
        "plt.title('Frequ√™ncia das palavras antes da lematiza√ß√£o')\n",
        "plt.show()\n",
        "\n",
        "# Gr√°fico de barras para o lema \"correr\" ap√≥s a lematiza√ß√£o\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(lema, frequencia_lema, color='lightgreen')\n",
        "plt.xlabel('Lema')\n",
        "plt.ylabel('Frequ√™ncia')\n",
        "plt.title('Frequ√™ncia do lema \"correr\" ap√≥s a lematiza√ß√£o')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Caso queira viisualizar as frequ√™ncia de cada token,\n",
        "# remova os coment√°rios as linhas a seguir\n",
        "#\n",
        "print(\"\\nFrequ√™ncia de palavras antes da lematiza√ß√£o:\")\n",
        "for palavra, frequencia in frequencia_original.items():\n",
        "    print(f\"{palavra}: {frequencia}\")\n",
        "\n",
        "print(\"\\n\\nFrequ√™ncia de palavras ap√≥s a lematiza√ß√£o:\")\n",
        "for palavra, frequencia in frequencia_lematizada.items():\n",
        "    print(f\"{palavra}: {frequencia}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmf63xiwF9M0"
      },
      "source": [
        "### 8.2: Atividade: Substitui√ß√£o do Conjunto de Frases e An√°lise de Resultados\n",
        "\n",
        "#### Objetivo:\n",
        "Nesta atividade, voc√™ substituir√° o conjunto de frases existente por um novo conjunto de frases em portugu√™s, executar√° o c√≥digo de processamento de linguagem natural (PLN) e analisar√° como as altera√ß√µes no conjunto de dados :influenciam os resultados da lematiza√ß√£o, remo√ß√£o de stopwords e an√°lise de frequ√™ncia de palavras.\n",
        "\n",
        "#### Passos da Atividade:\n",
        "\n",
        "1. **Etapa 1: Substitui√ß√£o do Conjunto de Frases**\n",
        "   - Substitua o conjunto de frases original por um novo conjunto de frases. Escolha ao menos dez novas frases que sejam diferentes em termos de estrutura, tema ou complexidade.\n",
        "   - As novas frases podem abordar um tema espec√≠fico (como esportes, pol√≠tica, ou tecnologia) ou serem mais variadas.\n",
        "\n",
        "2. **Etapa 2: Revis√£o do C√≥digo**\n",
        "   - Revise o c√≥digo existente para garantir que ele esteja preparado para processar o novo conjunto de frases.\n",
        "   - Verifique se as fun√ß√µes de tokeniza√ß√£o, remo√ß√£o de stopwords, e lematiza√ß√£o est√£o prontas para lidar com as novas frases.\n",
        "\n",
        "3. **Etapa 3: Execu√ß√£o do C√≥digo**\n",
        "   - Execute o c√≥digo com o novo conjunto de frases.\n",
        "   - Observe os resultados, incluindo a lista de tokens, as palavras lematizadas, e as frequ√™ncias das palavras antes e depois da lematiza√ß√£o.\n",
        "\n",
        "4. **Etapa 4: An√°lise dos Resultados**\n",
        "   - Compare os resultados obtidos com o novo conjunto de frases com os resultados anteriores (se dispon√≠vel).\n",
        "   - Analise como a mudan√ßa no conte√∫do das frases afetou:\n",
        "     - A lista de stopwords removidas.\n",
        "     - A efic√°cia da lematiza√ß√£o (quantas palavras foram corretamente reduzidas ao mesmo lema).\n",
        "     - A distribui√ß√£o de frequ√™ncias das palavras.\n",
        "   - Identifique quaisquer mudan√ßas not√°veis na lista de lemas √∫nicos.\n",
        "\n",
        "#### Requisitos:\n",
        "- Computador com Python instalado.\n",
        "- Bibliotecas necess√°rias: `nltk`, `spacy`.\n",
        "- C√≥digo existente para processamento de texto em portugu√™s.\n",
        "\n",
        "#### Instru√ß√µes:\n",
        "- Substitua o conjunto de frases no c√≥digo com um novo conjunto escolhido por voc√™.\n",
        "- Execute o c√≥digo revisado e observe os resultados.\n",
        "- Compare os resultados com qualquer execu√ß√£o anterior para entender o impacto das mudan√ßas.\n",
        "\n",
        "#### Objetivo Educacional:\n",
        "Esta atividade permite que voc√™ experimente como diferentes conjuntos de dados influenciam os resultados de um pipeline de PLN. Ao substituir as frases e analisar os resultados, voc√™ ter√° uma compreens√£o mais profunda de como a natureza dos dados textuais afeta a tokeniza√ß√£o, remo√ß√£o de stopwords, lematiza√ß√£o e an√°lise de frequ√™ncia. Essa atividade √© fundamental para aprender a adaptar t√©cnicas de PLN a diferentes contextos e tipos de texto."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
